{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PogNet3\n",
    "\n",
    "Multi-Vehicle Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Bz7A-XhOQ8L4"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import os, os.path\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\"\"\"Change to the data folder\"\"\"\n",
    "new_path = \"data/new_train/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "B6bHeDoMQ-y7"
   },
   "outputs": [],
   "source": [
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "\n",
    "    def __init__(self, data_path: str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, \"*\"))\n",
    "        self.pkl_list.sort()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pkl_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        pkl_path = self.pkl_list[idx]\n",
    "        with open(pkl_path, \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "\n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "# intialize a dataset\n",
    "train_dataset = ArgoverseDataset(data_path=new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "s33LYX3DREUh"
   },
   "outputs": [],
   "source": [
    "batch_sz = 100\n",
    "\n",
    "\n",
    "def my_collate_train(batch):\n",
    "    \"\"\"collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature]\"\"\"\n",
    "\n",
    "    batch_inp = []\n",
    "    batch_out = []\n",
    "\n",
    "    for scene in batch:\n",
    "        agent = scene[\"agent_id\"]\n",
    "        target = 0\n",
    "        for x in range(len(scene[\"track_id\"])):\n",
    "            if scene[\"track_id\"][x][0] == agent:\n",
    "                target = x\n",
    "        inp = [scene[\"p_in\"][target], scene[\"v_in\"][target]]\n",
    "        out = [scene[\"p_out\"][target], scene[\"v_out\"][target]]\n",
    "        batch_inp.append(inp)\n",
    "        batch_out.append(out)\n",
    "\n",
    "    # scene level #####################\n",
    "    # batch_inp = []\n",
    "    # batch_out = []\n",
    "    # for scene in batch:\n",
    "    #   mask = scene['car_mask'].flatten()==1\n",
    "    #   # print(np.count_nonzero(mask))\n",
    "    #   inp = [scene['p_in'][mask], scene['v_in'][mask]]\n",
    "    #   out = [scene['p_out'][mask], scene['v_out'][mask]]\n",
    "    #   batch_inp.append(inp)\n",
    "    #   batch_out.append(out)\n",
    "    ####################################\n",
    "\n",
    "    inp = torch.LongTensor(batch_inp)\n",
    "    out = torch.LongTensor(batch_out)\n",
    "    return [inp, out]\n",
    "\n",
    "\n",
    "def my_collate_train_multiple(batch):\n",
    "    \"\"\"collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature]\"\"\"\n",
    "    batch_inp = []\n",
    "    batch_out = []\n",
    "\n",
    "    for scene in batch:\n",
    "        agent = scene[\"agent_id\"]\n",
    "        target = 0\n",
    "        for x in range(len(scene[\"track_id\"])):\n",
    "            if scene[\"track_id\"][x][0] == agent:\n",
    "                target = x\n",
    "        inp = [scene[\"p_in\"][target], scene[\"v_in\"][target]]\n",
    "        out = [scene[\"p_out\"][target], scene[\"v_out\"][target]]\n",
    "\n",
    "        other_in = np.zeros((5, 2, 19, 2))  # need to permute to 2,5,19,2 later\n",
    "        other_out = np.zeros((5, 2, 30, 2))\n",
    "\n",
    "        other_in[0] = inp\n",
    "        other_out[0] = out\n",
    "\n",
    "        mask = scene[\"car_mask\"].flatten() == 1\n",
    "        mask = np.delete(mask, target)\n",
    "        mask = np.where(mask == True)[0]\n",
    "\n",
    "        if len(mask) >= 4:\n",
    "            temp = random.sample(mask.tolist(), 4)\n",
    "            for i in range(len(temp)):\n",
    "                other_in[i + 1] = [scene[\"p_in\"][temp[i]], scene[\"v_in\"][temp[i]]]\n",
    "                other_out[i + 1] = [scene[\"p_out\"][temp[i]], scene[\"v_out\"][temp[i]]]\n",
    "        else:\n",
    "            for i in range(len(mask)):\n",
    "                other_in[i + 1] = [scene[\"p_in\"][mask[i]], scene[\"v_in\"][mask[i]]]\n",
    "                other_out[i + 1] = [scene[\"p_out\"][mask[i]], scene[\"v_out\"][mask[i]]]\n",
    "            for i in range(4 - len(mask)):\n",
    "                other_in[i + 1 + len(mask)] = inp\n",
    "                other_out[i + 1 + len(mask)] = out\n",
    "\n",
    "        batch_inp.append(other_in.tolist())\n",
    "        batch_out.append(other_out.tolist())\n",
    "\n",
    "    # scene level #####################\n",
    "    # batch_inp = []\n",
    "    # batch_out = []\n",
    "    # for scene in batch:\n",
    "    #   mask = scene['car_mask'].flatten()==1\n",
    "    #   # print(np.count_nonzero(mask))\n",
    "    #   inp = [scene['p_in'][mask], scene['v_in'][mask]]\n",
    "    #   out = [scene['p_out'][mask], scene['v_out'][mask]]\n",
    "    #   batch_inp.append(inp)\n",
    "    #   batch_out.append(out)\n",
    "    ####################################\n",
    "\n",
    "    inp = torch.FloatTensor(batch_inp)\n",
    "    inp = inp.permute(2, 0, 1, 3, 4)  # p/v, batch, cars, points, x/y\n",
    "    out = torch.FloatTensor(batch_out)\n",
    "    out = out.permute(2, 0, 1, 3, 4)\n",
    "    return [inp, out]\n",
    "\n",
    "\n",
    "def my_collate_val(batch):\n",
    "    \"\"\"collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature]\"\"\"\n",
    "\n",
    "    inp = [[scene[\"p_in\"], scene[\"v_in\"]] for scene in batch]\n",
    "    mask = [scene[\"car_mask\"] for scene in batch]\n",
    "\n",
    "    inp = torch.FloatTensor(inp)\n",
    "    mask = torch.FloatTensor(mask)\n",
    "    return [inp, mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "G7YyLqs1q2_S"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class Trajectory(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Trajectory, self).__init__()\n",
    "\n",
    "        self.p_in = nn.Linear(2, 32)  # N, 19, 2\n",
    "        self.v_in = nn.Linear(2, 32)  # N, 19, 2\n",
    "\n",
    "        self.encoder = nn.LSTM(64, 64, 1)  # input 19, N, 64 output 1, N, 64\n",
    "\n",
    "        self.decoder_p = nn.LSTM(64, 128, 1)  # input 30, N, 64 output 30, N, 128\n",
    "        self.decoder_v = nn.LSTM(64, 128, 1)  # input 30, N, 64 output 30, N, 128\n",
    "\n",
    "        self.p_out = nn.Linear(128, 2)\n",
    "        self.v_out = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, p, v):\n",
    "        batch = p.shape[0]\n",
    "        x_p = self.p_in(p)\n",
    "        x_v = self.v_in(v)\n",
    "\n",
    "        x = torch.cat((x_p, x_v), dim=2)\n",
    "        x = x.permute(1, 0, 2)\n",
    "\n",
    "        _, (state_h, _) = self.encoder(x)\n",
    "\n",
    "        x = state_h.repeat(30, 1, 1)\n",
    "\n",
    "        x_p, _ = self.decoder_p(x)\n",
    "        x_v, _ = self.decoder_v(x)\n",
    "\n",
    "        x_p = x_p.permute(1, 0, 2)\n",
    "        x_v = x_v.permute(1, 0, 2)\n",
    "\n",
    "        x_p = self.p_out(x_p)\n",
    "        x_v = self.v_out(x_v)\n",
    "\n",
    "        return x_p, x_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8wqSU86YvIgT",
    "outputId": "3fc04c5d-5d03-4f1b-e63f-735139370517",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LENGTH OF TRAIN LOADER DATASET: 205942\n",
      "LENGTH OF TRAIN DATA: 164753 \n",
      "LENGTH OF VAL DATA: 41189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch [1/20]: 100%|██████████| 1648/1648 [01:03<00:00, 26.11it/s, loss=17.6]\n",
      "Val.  Epoch [1/20]: 100%|██████████| 412/412 [00:18<00:00, 21.86it/s, loss=1.65] \n",
      "Train Epoch [2/20]: 100%|██████████| 1648/1648 [01:16<00:00, 21.55it/s, loss=6.22]\n",
      "Val.  Epoch [2/20]: 100%|██████████| 412/412 [00:20<00:00, 20.30it/s, loss=1.6]  \n",
      "Train Epoch [3/20]: 100%|██████████| 1648/1648 [01:22<00:00, 20.00it/s, loss=5.43]\n",
      "Val.  Epoch [3/20]: 100%|██████████| 412/412 [00:20<00:00, 20.25it/s, loss=1.29] \n",
      "Train Epoch [4/20]: 100%|██████████| 1648/1648 [01:23<00:00, 19.84it/s, loss=4.86]\n",
      "Val.  Epoch [4/20]: 100%|██████████| 412/412 [00:20<00:00, 20.07it/s, loss=1.11] \n",
      "Train Epoch [5/20]: 100%|██████████| 1648/1648 [01:23<00:00, 19.83it/s, loss=4.42]\n",
      "Val.  Epoch [5/20]: 100%|██████████| 412/412 [00:20<00:00, 20.29it/s, loss=0.592]\n",
      "Train Epoch [6/20]: 100%|██████████| 1648/1648 [01:22<00:00, 19.94it/s, loss=4.05]\n",
      "Val.  Epoch [6/20]: 100%|██████████| 412/412 [00:20<00:00, 20.11it/s, loss=1.68] \n",
      "Train Epoch [7/20]: 100%|██████████| 1648/1648 [01:22<00:00, 19.97it/s, loss=3.9] \n",
      "Val.  Epoch [7/20]: 100%|██████████| 412/412 [00:20<00:00, 20.14it/s, loss=1.22] \n",
      "Train Epoch [8/20]: 100%|██████████| 1648/1648 [01:22<00:00, 19.96it/s, loss=3.61]\n",
      "Val.  Epoch [8/20]: 100%|██████████| 412/412 [00:20<00:00, 19.99it/s, loss=0.506]\n",
      "Train Epoch [9/20]: 100%|██████████| 1648/1648 [01:22<00:00, 19.87it/s, loss=3.36]\n",
      "Val.  Epoch [9/20]: 100%|██████████| 412/412 [00:20<00:00, 20.12it/s, loss=0.913]\n",
      "Train Epoch [10/20]: 100%|██████████| 1648/1648 [01:23<00:00, 19.73it/s, loss=3.17]\n",
      "Val.  Epoch [10/20]: 100%|██████████| 412/412 [00:20<00:00, 20.12it/s, loss=0.732]\n",
      "Train Epoch [11/20]: 100%|██████████| 1648/1648 [01:23<00:00, 19.72it/s, loss=3.13]\n",
      "Val.  Epoch [11/20]: 100%|██████████| 412/412 [00:20<00:00, 20.01it/s, loss=0.721]\n",
      "Train Epoch [12/20]: 100%|██████████| 1648/1648 [01:23<00:00, 19.75it/s, loss=2.95]\n",
      "Val.  Epoch [12/20]: 100%|██████████| 412/412 [00:20<00:00, 19.98it/s, loss=0.742]\n",
      "Train Epoch [13/20]: 100%|██████████| 1648/1648 [01:23<00:00, 19.69it/s, loss=2.8] \n",
      "Val.  Epoch [13/20]: 100%|██████████| 412/412 [00:20<00:00, 19.80it/s, loss=1.01] \n",
      "Train Epoch [14/20]: 100%|██████████| 1648/1648 [01:23<00:00, 19.63it/s, loss=2.75]\n",
      "Val.  Epoch [14/20]: 100%|██████████| 412/412 [00:20<00:00, 19.93it/s, loss=0.475]\n",
      "Train Epoch [15/20]: 100%|██████████| 1648/1648 [01:24<00:00, 19.55it/s, loss=2.66] \n",
      "Val.  Epoch [15/20]: 100%|██████████| 412/412 [00:20<00:00, 19.93it/s, loss=0.689]\n",
      "Train Epoch [16/20]: 100%|██████████| 1648/1648 [01:23<00:00, 19.65it/s, loss=2.54]\n",
      "Val.  Epoch [16/20]: 100%|██████████| 412/412 [00:20<00:00, 19.87it/s, loss=0.334] \n",
      "Train Epoch [17/20]: 100%|██████████| 1648/1648 [01:23<00:00, 19.65it/s, loss=2.49] \n",
      "Val.  Epoch [17/20]: 100%|██████████| 412/412 [00:20<00:00, 19.92it/s, loss=0.759]\n",
      "Train Epoch [18/20]: 100%|██████████| 1648/1648 [01:24<00:00, 19.60it/s, loss=2.43]\n",
      "Val.  Epoch [18/20]: 100%|██████████| 412/412 [00:20<00:00, 19.76it/s, loss=0.499]\n",
      "Train Epoch [19/20]: 100%|██████████| 1648/1648 [01:23<00:00, 19.65it/s, loss=2.39]\n",
      "Val.  Epoch [19/20]: 100%|██████████| 412/412 [00:20<00:00, 19.94it/s, loss=0.639]\n",
      "Train Epoch [20/20]: 100%|██████████| 1648/1648 [01:24<00:00, 19.61it/s, loss=2.31]\n",
      "Val.  Epoch [20/20]: 100%|██████████| 412/412 [00:21<00:00, 19.53it/s, loss=0.546]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Multi-Car Training + Validation\n",
    "Normalization: /4800, /100\n",
    "\"\"\"\n",
    "\n",
    "batch_sz = 100\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_sz,\n",
    "    shuffle=False,\n",
    "    collate_fn=my_collate_train_multiple,\n",
    "    num_workers=2,\n",
    ")\n",
    "\n",
    "train_size = int(0.8 * len(train_loader.dataset))\n",
    "val_size = len(train_loader.dataset) - train_size\n",
    "train_data, val_data = torch.utils.data.random_split(\n",
    "    train_loader.dataset, [train_size, val_size]\n",
    ")\n",
    "\n",
    "print(\"\\nLENGTH OF TRAIN LOADER DATASET:\", len(train_loader.dataset))\n",
    "print(\"LENGTH OF TRAIN DATA:\", len(train_data), \"\\nLENGTH OF VAL DATA:\", len(val_data))\n",
    "\n",
    "train_data = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=batch_sz,\n",
    "    shuffle=False,\n",
    "    collate_fn=my_collate_train_multiple,\n",
    "    num_workers=2,\n",
    ")\n",
    "val_data = DataLoader(\n",
    "    val_data,\n",
    "    batch_size=batch_sz,\n",
    "    shuffle=False,\n",
    "    collate_fn=my_collate_train_multiple,\n",
    "    num_workers=2,\n",
    ")\n",
    "model = Trajectory().to(device)\n",
    "\n",
    "my_optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epoch = 20  # takes around 20 epochs to converge\n",
    "number = 5  # number of cars in each\n",
    "\n",
    "for i in range(epoch):\n",
    "\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    train_loop = tqdm(enumerate(train_data), total=len(train_data))\n",
    "\n",
    "    for i_batch, sample_batch in train_loop:\n",
    "\n",
    "        inp, out = sample_batch\n",
    "        batch = inp.shape[1]\n",
    "\n",
    "        p_in = (inp[0].reshape(batch * number, 19, 2).to(device)) / 4800.\n",
    "        v_in = inp[1].reshape(batch * number, 19, 2).to(device) / 100.\n",
    "        p_out = (out[0].reshape(batch * number, 30, 2).to(device)) /4800.\n",
    "        v_out = out[1].reshape(batch * number, 30, 2).to(device) / 100.\n",
    "\n",
    "        pred = model(p_in, v_in)\n",
    "\n",
    "        loss = 0\n",
    "        p_criteria = nn.MSELoss()\n",
    "        p_loss = torch.sqrt(p_criteria(pred[0], p_out))\n",
    "\n",
    "        v_criteria = nn.MSELoss()\n",
    "        v_loss = torch.sqrt(v_criteria(pred[1], v_out))\n",
    "\n",
    "        loss = p_loss + v_loss\n",
    "        epoch_loss += p_loss\n",
    "\n",
    "        my_optim.zero_grad()\n",
    "        loss.backward()\n",
    "        my_optim.step()\n",
    "\n",
    "        train_loop.set_description(f\"Train Epoch [{i + 1}/{epoch}]\")\n",
    "        train_loop.set_postfix(loss=epoch_loss.item())\n",
    "\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    val_loop = tqdm(enumerate(val_data), total=len(val_data))\n",
    "    for i_batch, sample_batch in val_loop:\n",
    "        inp, out = sample_batch\n",
    "        batch = inp.shape[1]\n",
    "\n",
    "        p_in = (inp[0].reshape(batch * number, 19, 2).to(device)) / 4800.\n",
    "        v_in = inp[1].reshape(batch * number, 19, 2).to(device) / 100.\n",
    "        p_out = (out[0].reshape(batch * number, 30, 2).to(device)) / 4800.\n",
    "        v_out = out[1].reshape(batch * number, 30, 2).to(device) / 100.\n",
    "\n",
    "        pred = model(p_in, v_in)\n",
    "\n",
    "        loss = 0\n",
    "        p_criteria = nn.MSELoss()\n",
    "        p_loss = torch.sqrt(p_criteria(pred[0], p_out))\n",
    "\n",
    "        epoch_loss += p_loss\n",
    "\n",
    "        val_loop.set_description(f\"Val.  Epoch [{i + 1}/{epoch}]\")\n",
    "        val_loop.set_postfix(loss=epoch_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LENGTH OF TRAIN LOADER DATASET: 205942\n",
      "LENGTH OF TRAIN DATA: 164753 \n",
      "LENGTH OF VAL DATA: 41189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch [1/20]: 100%|██████████| 1648/1648 [01:02<00:00, 26.57it/s, loss=22.7]\n",
      "Val.  Epoch [1/20]: 100%|██████████| 412/412 [00:16<00:00, 24.39it/s, loss=2.12] \n",
      "Train Epoch [2/20]: 100%|██████████| 1648/1648 [01:05<00:00, 25.18it/s, loss=8.06]\n",
      "Val.  Epoch [2/20]: 100%|██████████| 412/412 [00:18<00:00, 22.88it/s, loss=1.98] \n",
      "Train Epoch [3/20]: 100%|██████████| 1648/1648 [01:19<00:00, 20.67it/s, loss=6.91]\n",
      "Val.  Epoch [3/20]: 100%|██████████| 412/412 [00:16<00:00, 24.42it/s, loss=2.13] \n",
      "Train Epoch [4/20]: 100%|██████████| 1648/1648 [01:15<00:00, 21.71it/s, loss=6.41]\n",
      "Val.  Epoch [4/20]: 100%|██████████| 412/412 [00:20<00:00, 20.32it/s, loss=1.24] \n",
      "Train Epoch [5/20]: 100%|██████████| 1648/1648 [01:10<00:00, 23.48it/s, loss=5.9] \n",
      "Val.  Epoch [5/20]: 100%|██████████| 412/412 [00:20<00:00, 20.28it/s, loss=1.66] \n",
      "Train Epoch [6/20]: 100%|██████████| 1648/1648 [01:17<00:00, 21.32it/s, loss=5.34]\n",
      "Val.  Epoch [6/20]: 100%|██████████| 412/412 [00:14<00:00, 29.28it/s, loss=1.59] \n",
      "Train Epoch [7/20]: 100%|██████████| 1648/1648 [01:15<00:00, 21.94it/s, loss=5.33]\n",
      "Val.  Epoch [7/20]: 100%|██████████| 412/412 [00:20<00:00, 20.51it/s, loss=1.04] \n",
      "Train Epoch [8/20]: 100%|██████████| 1648/1648 [01:08<00:00, 23.96it/s, loss=4.86]\n",
      "Val.  Epoch [8/20]: 100%|██████████| 412/412 [00:20<00:00, 19.96it/s, loss=1.16] \n",
      "Train Epoch [9/20]: 100%|██████████| 1648/1648 [01:17<00:00, 21.18it/s, loss=4.67]\n",
      "Val.  Epoch [9/20]: 100%|██████████| 412/412 [00:14<00:00, 28.07it/s, loss=1.15] \n",
      "Train Epoch [10/20]: 100%|██████████| 1648/1648 [01:19<00:00, 20.69it/s, loss=4.4] \n",
      "Val.  Epoch [10/20]: 100%|██████████| 412/412 [00:20<00:00, 20.08it/s, loss=1.01] \n",
      "Train Epoch [11/20]: 100%|██████████| 1648/1648 [01:10<00:00, 23.22it/s, loss=4.29]\n",
      "Val.  Epoch [11/20]: 100%|██████████| 412/412 [00:21<00:00, 19.57it/s, loss=0.725]\n",
      "Train Epoch [12/20]: 100%|██████████| 1648/1648 [01:19<00:00, 20.82it/s, loss=4.23]\n",
      "Val.  Epoch [12/20]: 100%|██████████| 412/412 [00:16<00:00, 24.51it/s, loss=1.05] \n",
      "Train Epoch [13/20]: 100%|██████████| 1648/1648 [01:21<00:00, 20.25it/s, loss=4.1] \n",
      "Val.  Epoch [13/20]: 100%|██████████| 412/412 [00:20<00:00, 20.03it/s, loss=1.16] \n",
      "Train Epoch [14/20]: 100%|██████████| 1648/1648 [01:11<00:00, 22.94it/s, loss=4.05]\n",
      "Val.  Epoch [14/20]: 100%|██████████| 412/412 [00:20<00:00, 19.91it/s, loss=1.13] \n",
      "Train Epoch [15/20]: 100%|██████████| 1648/1648 [01:17<00:00, 21.26it/s, loss=3.75]\n",
      "Val.  Epoch [15/20]: 100%|██████████| 412/412 [00:17<00:00, 23.58it/s, loss=1.11] \n",
      "Train Epoch [16/20]: 100%|██████████| 1648/1648 [01:24<00:00, 19.62it/s, loss=3.65]\n",
      "Val.  Epoch [16/20]: 100%|██████████| 412/412 [00:21<00:00, 19.04it/s, loss=0.798]\n",
      "Train Epoch [17/20]: 100%|██████████| 1648/1648 [01:15<00:00, 21.79it/s, loss=3.64]\n",
      "Val.  Epoch [17/20]: 100%|██████████| 412/412 [00:21<00:00, 19.24it/s, loss=0.945]\n",
      "Train Epoch [18/20]: 100%|██████████| 1648/1648 [01:19<00:00, 20.82it/s, loss=3.5] \n",
      "Val.  Epoch [18/20]: 100%|██████████| 412/412 [00:17<00:00, 23.47it/s, loss=0.828]\n",
      "Train Epoch [19/20]: 100%|██████████| 1648/1648 [01:24<00:00, 19.40it/s, loss=3.44]\n",
      "Val.  Epoch [19/20]: 100%|██████████| 412/412 [00:21<00:00, 19.30it/s, loss=1]    \n",
      "Train Epoch [20/20]: 100%|██████████| 1648/1648 [01:15<00:00, 21.77it/s, loss=3.41]\n",
      "Val.  Epoch [20/20]: 100%|██████████| 412/412 [00:21<00:00, 19.09it/s, loss=1.05] \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Multi-Car Training + Validation\n",
    "Normalization: /2400, /85\n",
    "\"\"\"\n",
    "\n",
    "batch_sz = 100\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_sz,\n",
    "    shuffle=False,\n",
    "    collate_fn=my_collate_train_multiple,\n",
    "    num_workers=2,\n",
    ")\n",
    "\n",
    "train_size = int(0.8 * len(train_loader.dataset))\n",
    "val_size = len(train_loader.dataset) - train_size\n",
    "train_data, val_data = torch.utils.data.random_split(\n",
    "    train_loader.dataset, [train_size, val_size]\n",
    ")\n",
    "\n",
    "print(\"\\nLENGTH OF TRAIN LOADER DATASET:\", len(train_loader.dataset))\n",
    "print(\"LENGTH OF TRAIN DATA:\", len(train_data), \"\\nLENGTH OF VAL DATA:\", len(val_data))\n",
    "\n",
    "train_data = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=batch_sz,\n",
    "    shuffle=False,\n",
    "    collate_fn=my_collate_train_multiple,\n",
    "    num_workers=2,\n",
    ")\n",
    "val_data = DataLoader(\n",
    "    val_data,\n",
    "    batch_size=batch_sz,\n",
    "    shuffle=False,\n",
    "    collate_fn=my_collate_train_multiple,\n",
    "    num_workers=2,\n",
    ")\n",
    "model = Trajectory().to(device)\n",
    "\n",
    "my_optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epoch = 20  # takes around 20 epochs to converge\n",
    "number = 5  # number of cars in each\n",
    "\n",
    "for i in range(epoch):\n",
    "\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    train_loop = tqdm(enumerate(train_data), total=len(train_data))\n",
    "\n",
    "    for i_batch, sample_batch in train_loop:\n",
    "\n",
    "        inp, out = sample_batch\n",
    "        batch = inp.shape[1]\n",
    "\n",
    "        p_in = ((inp[0].reshape(batch * number, 19, 2).to(device)) - 2400.) / 2400.\n",
    "        v_in = inp[1].reshape(batch * number, 19, 2).to(device) / 85.\n",
    "        p_out = ((out[0].reshape(batch * number, 30, 2).to(device)) - 2400.) / 2400\n",
    "        v_out = out[1].reshape(batch * number, 30, 2).to(device) / 85.\n",
    "\n",
    "        pred = model(p_in, v_in)\n",
    "\n",
    "        loss = 0\n",
    "        p_criteria = nn.MSELoss()\n",
    "        p_loss = torch.sqrt(p_criteria(pred[0], p_out))\n",
    "\n",
    "        v_criteria = nn.MSELoss()\n",
    "        v_loss = torch.sqrt(v_criteria(pred[1], v_out))\n",
    "\n",
    "        loss = p_loss + v_loss\n",
    "        epoch_loss += p_loss\n",
    "\n",
    "        my_optim.zero_grad()\n",
    "        loss.backward()\n",
    "        my_optim.step()\n",
    "\n",
    "        train_loop.set_description(f\"Train Epoch [{i + 1}/{epoch}]\")\n",
    "        train_loop.set_postfix(loss=epoch_loss.item())\n",
    "\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    val_loop = tqdm(enumerate(val_data), total=len(val_data))\n",
    "    for i_batch, sample_batch in val_loop:\n",
    "        inp, out = sample_batch\n",
    "        batch = inp.shape[1]\n",
    "\n",
    "        p_in = ((inp[0].reshape(batch * number, 19, 2).to(device)) - 2400.) / 2400.\n",
    "        v_in = inp[1].reshape(batch * number, 19, 2).to(device) / 85.\n",
    "        p_out = ((out[0].reshape(batch * number, 30, 2).to(device)) - 2400.) / 2400.\n",
    "        v_out = out[1].reshape(batch * number, 30, 2).to(device) / 85.\n",
    "\n",
    "        pred = model(p_in, v_in)\n",
    "\n",
    "        loss = 0\n",
    "        p_criteria = nn.MSELoss()\n",
    "        p_loss = torch.sqrt(p_criteria(pred[0], p_out))\n",
    "\n",
    "        epoch_loss += p_loss\n",
    "\n",
    "        val_loop.set_description(f\"Val.  Epoch [{i + 1}/{epoch}]\")\n",
    "        val_loop.set_postfix(loss=epoch_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Multi-Car Training for Submission\n",
    "Normalization: /4800, /100\n",
    "\"\"\"\n",
    "\n",
    "batch_sz = 100\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_sz,\n",
    "    shuffle=False,\n",
    "    collate_fn=my_collate_train_multiple,\n",
    "    num_workers=2,\n",
    ")\n",
    "\n",
    "print(\"\\nLENGTH OF TRAIN LOADER DATASET:\", len(train_loader.dataset))\n",
    "print(\"LENGTH OF TRAIN DATA:\", len(train_data))\n",
    "\n",
    "model = Trajectory().to(device)\n",
    "\n",
    "my_optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epoch = 20  # takes around 20 epochs to converge\n",
    "number = 5  # number of cars in each\n",
    "\n",
    "for i in range(epoch):\n",
    "\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    train_loop = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "\n",
    "    for i_batch, sample_batch in train_loop:\n",
    "\n",
    "        inp, out = sample_batch\n",
    "        batch = inp.shape[1]\n",
    "\n",
    "        p_in = (inp[0].reshape(batch * number, 19, 2).to(device)) / 4800.\n",
    "        v_in = inp[1].reshape(batch * number, 19, 2).to(device) / 100.\n",
    "        p_out = (out[0].reshape(batch * number, 30, 2).to(device)) /4800.\n",
    "        v_out = out[1].reshape(batch * number, 30, 2).to(device) / 100.\n",
    "\n",
    "        pred = model(p_in, v_in)\n",
    "\n",
    "        loss = 0\n",
    "        p_criteria = nn.MSELoss()\n",
    "        p_loss = torch.sqrt(p_criteria(pred[0], p_out))\n",
    "\n",
    "        v_criteria = nn.MSELoss()\n",
    "        v_loss = torch.sqrt(v_criteria(pred[1], v_out))\n",
    "\n",
    "        loss = p_loss + v_loss\n",
    "        epoch_loss += p_loss\n",
    "\n",
    "        my_optim.zero_grad()\n",
    "        loss.backward()\n",
    "        my_optim.step()\n",
    "\n",
    "        train_loop.set_description(f\"Train Epoch [{i + 1}/{epoch}]\")\n",
    "        train_loop.set_postfix(loss=epoch_loss.item())\n",
    "\n",
    "    model.eval()\n",
    "    epoch_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-uQ2Y3O0ELNN"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "for i_batch, sample_batch in enumerate(train_loader):\n",
    "    inp, out = sample_batch\n",
    "    batch = inp.shape[0]\n",
    "\n",
    "    p_in = (\n",
    "        inp[:, 0].reshape(batch * number, 19, 2).to(device)\n",
    "    ) / 4800.0  # -2400.)/2400.\n",
    "    v_in = inp[:, 1].reshape(batch * number, 19, 2).to(device) / 100.0\n",
    "    p_out = (\n",
    "        out[:, 0].reshape(batch * number, 30, 2).to(device)\n",
    "    ) / 4800.0  # -2400.)/2400.\n",
    "    v_out = out[:, 1].reshape(batch * number, 30, 2).to(device) / 100.0\n",
    "\n",
    "    pred = model(p_in, v_in)\n",
    "    print(pred[0][9] * 4800, p_out[9] * 4800)\n",
    "    print(torch.sum(torch.subtract(pred[0][9] * 4800, p_out[9] * 4800)))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QhL6nFx1q3bm"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "model.eval()\n",
    "temp = []\n",
    "\n",
    "new_path = \"data/new_val_in/\"\n",
    "val_dataset = ArgoverseDataset(data_path=new_path)\n",
    "\n",
    "top = []\n",
    "top.append(\"ID\")\n",
    "for i in range(60):\n",
    "    top.append(\"v\" + str(i + 1))\n",
    "temp.append(top)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in val_dataset:\n",
    "        row = []\n",
    "        scene = i[\"scene_idx\"]\n",
    "        agent = i[\"agent_id\"]\n",
    "        target = 0\n",
    "        for x in range(len(i[\"track_id\"])):\n",
    "            if i[\"track_id\"][x][0] == agent:\n",
    "                target = x\n",
    "\n",
    "        p_in = torch.LongTensor(i[\"p_in\"])\n",
    "        v_in = torch.LongTensor(i[\"v_in\"])\n",
    "\n",
    "        p_in = (p_in.reshape(60, 19, 2).to(device)) / 4800.0\n",
    "        v_in = v_in.reshape(60, 19, 2).to(device) / 100.0\n",
    "\n",
    "        pred = model(p_in, v_in)\n",
    "\n",
    "        pred_out = pred[0] * 4800.0\n",
    "\n",
    "        output = pred_out[target]\n",
    "\n",
    "        row.append(scene)\n",
    "        row = row + torch.flatten(output).cpu().detach().numpy().tolist()\n",
    "        temp.append(row)\n",
    "\n",
    "with open(\"submission9.csv\", \"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "151B_Kaggle_Comp",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
