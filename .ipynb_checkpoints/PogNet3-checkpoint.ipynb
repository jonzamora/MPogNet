{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Bz7A-XhOQ8L4"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\"\"\"Change to the data folder\"\"\"\n",
    "new_path = \"data/new_train/\"\n",
    "\n",
    "# number of sequences in each dataset\n",
    "# train:205942  val:3200 test: 36272 \n",
    "# sequences sampled at 10HZ rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "B6bHeDoMQ-y7"
   },
   "outputs": [],
   "source": [
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, data_path: str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pkl_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        pkl_path = self.pkl_list[idx]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "# intialize a dataset\n",
    "train_dataset  = ArgoverseDataset(data_path=new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "s33LYX3DREUh"
   },
   "outputs": [],
   "source": [
    "batch_sz = 100\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def my_collate_train(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "\n",
    "    batch_inp = []\n",
    "    batch_out = []\n",
    "\n",
    "    for scene in batch:\n",
    "      agent = scene['agent_id']\n",
    "      target = 0\n",
    "      for x in range(len(scene['track_id'])):\n",
    "        if scene['track_id'][x][0] == agent:\n",
    "          target = x\n",
    "      inp = [scene['p_in'][target], scene['v_in'][target]]\n",
    "      out = [scene['p_out'][target], scene['v_out'][target]]\n",
    "      batch_inp.append(inp)\n",
    "      batch_out.append(out)\n",
    "\n",
    "    # scene level #####################\n",
    "    # batch_inp = []\n",
    "    # batch_out = []\n",
    "    # for scene in batch:\n",
    "    #   mask = scene['car_mask'].flatten()==1\n",
    "    #   # print(np.count_nonzero(mask))\n",
    "    #   inp = [scene['p_in'][mask], scene['v_in'][mask]]\n",
    "    #   out = [scene['p_out'][mask], scene['v_out'][mask]]\n",
    "    #   batch_inp.append(inp)\n",
    "    #   batch_out.append(out)\n",
    "    ####################################\n",
    "\n",
    "\n",
    "    inp = torch.LongTensor(batch_inp)\n",
    "    out = torch.LongTensor(batch_out)\n",
    "    return [inp, out]\n",
    "\n",
    "def my_collate_train_multiple(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "\n",
    "    batch_inp = []\n",
    "    batch_out = []\n",
    "\n",
    "    for scene in batch:\n",
    "      agent = scene['agent_id']\n",
    "      target = 0\n",
    "      for x in range(len(scene['track_id'])):\n",
    "        if scene['track_id'][x][0] == agent:\n",
    "          target = x\n",
    "      inp = [scene['p_in'][target], scene['v_in'][target]]\n",
    "      out = [scene['p_out'][target], scene['v_out'][target]]\n",
    "\n",
    "      other_in = np.zeros((5,2,19,2)) # need to permute to 2,5,19,2 later\n",
    "      other_out = np.zeros((5,2,30,2))\n",
    "\n",
    "      other_in[0] = inp\n",
    "      other_out[0] = out\n",
    "\n",
    "      mask = scene['car_mask'].flatten()==1\n",
    "      mask = np.delete(mask,target)\n",
    "      mask = np.where(mask == True)[0]\n",
    "\n",
    "      if(len(mask)>=4):\n",
    "        temp = random.sample(mask.tolist(),4)\n",
    "        for i in range(len(temp)):\n",
    "          other_in[i+1] = [scene['p_in'][temp[i]], scene['v_in'][temp[i]]]\n",
    "          other_out[i+1] = [scene['p_out'][temp[i]], scene['v_out'][temp[i]]]\n",
    "      else:\n",
    "        for i in range(len(mask)):\n",
    "          other_in[i+1] = [scene['p_in'][mask[i]], scene['v_in'][mask[i]]]\n",
    "          other_out[i+1] = [scene['p_out'][mask[i]], scene['v_out'][mask[i]]]\n",
    "        for i in range(4-len(mask)):\n",
    "          other_in[i+1+len(mask)] = inp\n",
    "          other_out[i+1+len(mask)] = out\n",
    "\n",
    "      batch_inp.append(other_in.tolist())\n",
    "      batch_out.append(other_out.tolist())\n",
    "\n",
    "    # scene level #####################\n",
    "    # batch_inp = []\n",
    "    # batch_out = []\n",
    "    # for scene in batch:\n",
    "    #   mask = scene['car_mask'].flatten()==1\n",
    "    #   # print(np.count_nonzero(mask))\n",
    "    #   inp = [scene['p_in'][mask], scene['v_in'][mask]]\n",
    "    #   out = [scene['p_out'][mask], scene['v_out'][mask]]\n",
    "    #   batch_inp.append(inp)\n",
    "    #   batch_out.append(out)\n",
    "    ####################################\n",
    "\n",
    "\n",
    "    inp = torch.LongTensor(batch_inp)\n",
    "    inp = inp.permute(2,0,1,3,4) # p/v, batch, cars, points, x/y\n",
    "    out = torch.LongTensor(batch_out)\n",
    "    out = out.permute(2,0,1,3,4) \n",
    "    return [inp, out]\n",
    "\n",
    "def my_collate_val(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "\n",
    "    inp = [[scene['p_in'], scene['v_in']] for scene in batch]\n",
    "    mask = [scene['car_mask'] for scene in batch]\n",
    "\n",
    "    inp = torch.LongTensor(inp)\n",
    "    mask = torch.LongTensor(mask)\n",
    "    return [inp, mask]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G7YyLqs1q2_S"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "start with initial 19 points and zero fill remaining\n",
    "'''\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class Trajectory(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Trajectory, self).__init__()\n",
    "\n",
    "        self.p_in = nn.Linear(2,32) # N, 19, 2\n",
    "        self.v_in = nn.Linear(2,32) # N, 19, 2\n",
    "        \n",
    "        self.encoder = nn.LSTM(64, 64, 1) # input 19, N, 64 output 1, N, 64 \n",
    "\n",
    "        self.decoder_p = nn.LSTM(64, 64, 1) # input 30, N, 64 output 30, N, 64\n",
    "        self.decoder_v = nn.LSTM(64, 64,1) # input 30, N, 64 output 30, N, 64\n",
    "\n",
    "        self.p_out = nn.Linear(128,2)\n",
    "        self.v_out = nn.Linear(128,2)\n",
    "\n",
    "    def forward(self, p, v):\n",
    "        batch = p.shape[0]\n",
    "        x_p = self.p_in(p)\n",
    "        x_v = self.v_in(v)\n",
    "\n",
    "        x = torch.cat((x_p,x_v),dim=2)\n",
    "        x = x.permute(1,0,2)\n",
    "\n",
    "        _,(state_h) = self.encoder(x)\n",
    "\n",
    "        temp = torch.zeros(11,batch,64)\n",
    "        x = torch.cat((x,temp),dim=0)\n",
    "\n",
    "        x_p,_ = self.decoder_p(x,state_h)\n",
    "        x_v,_ = self.decoder_v(x,state_h)\n",
    "\n",
    "        x_p = x_p.permute(1,0,2)\n",
    "        x_v = x_v.permute(1,0,2)\n",
    "\n",
    "        x_p = self.p_out(x_p)\n",
    "        x_v = self.v_out(x_v)\n",
    "\n",
    "        # batch 50, 345s per epoch\n",
    "        # p to p -> 9.21 after 10 epochs\n",
    "        # p + v to p -> 8.8 after 10 epochs\n",
    "        # p + v to p +v -> 6.65 after 10 epochs\n",
    "\n",
    "        # batch 100, 345s per epoch\n",
    "        # p + v to p +v -> 4.5 after 10 epochs\n",
    "\n",
    "        return x_p , x_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b0bsBqBwn6yQ"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Recursive per point\n",
    "'''\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class Trajectory(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Trajectory, self).__init__()\n",
    "\n",
    "        self.p_in = nn.Linear(2,32) # N, 19, 2\n",
    "        self.v_in = nn.Linear(2,32) # N, 19, 2\n",
    "        \n",
    "        self.encoder = nn.LSTM(64, 64, 1) # input 19, N, 64 output 1, N, 64 \n",
    "\n",
    "        self.decoder_p = nn.LSTM(64, 64, 1) # input 30, N, 64 output 30, N, 64\n",
    "        self.decoder_v = nn.LSTM(64, 64,1) # input 30, N, 64 output 30, N, 64\n",
    "\n",
    "        self.recurse_p =  nn.Linear(2,32)\n",
    "        self.recurse_v = nn.Linear(2,32)\n",
    " \n",
    "        self.p_out = nn.Linear(64,2)\n",
    "        self.v_out = nn.Linear(64,2)\n",
    "\n",
    "    def forward(self, p, v):\n",
    "        batch = p.shape[0]\n",
    "        x_p = self.p_in(p)\n",
    "        x_v = self.v_in(v)\n",
    "\n",
    "        x = torch.cat((x_p,x_v),dim=2)\n",
    "        x = x.permute(1,0,2)\n",
    "\n",
    "        _,(state_h) = self.encoder(x)\n",
    "\n",
    "        temp_p = torch.zeros(30,batch,2).to(device) # output of p\n",
    "        temp_v = torch.zeros(30,batch,2).to(device)\n",
    "       \n",
    "        decoder_p_inp = torch.unsqueeze(x[-1],0)\n",
    "        decoder_v_inp = torch.unsqueeze(x[-1],0)\n",
    "        state_p = state_h\n",
    "        state_v = state_h\n",
    "\n",
    "        for i in range(30):\n",
    "          x_p,state_p = self.decoder_p(decoder_p_inp, state_p)\n",
    "          x_v,state_v = self.decoder_v(decoder_v_inp, state_v)\n",
    "\n",
    "          x_p = self.p_out(x_p)\n",
    "          x_v = self.v_out(x_v)\n",
    "\n",
    "          temp_p[i] = x_p\n",
    "          temp_v[i] = x_v\n",
    "\n",
    "          x_p = self.recurse_p(x_p)\n",
    "          x_v = self.recurse_v(x_v)\n",
    "\n",
    "          x = torch.cat((x_p,x_v),dim=2)\n",
    "\n",
    "          decoder_p_inp = x\n",
    "          decoder_v_inp = x\n",
    "\n",
    "        temp_p = temp_p.permute(1,0,2)\n",
    "        temp_v = temp_v.permute(1,0,2)\n",
    "        return temp_p, temp_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7_ENkqUjWfkn"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Edward's Tests, bigger\n",
    "'''\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class Trajectory(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Trajectory, self).__init__()\n",
    "\n",
    "        self.p_in = nn.Linear(2,32) # N, 19, 2\n",
    "        self.v_in = nn.Linear(2,32) # N, 19, 2\n",
    "        \n",
    "        self.encoder = nn.LSTM(64, 128, 1) # input 19, N, 64 output 19, N, 128\n",
    "        self.encoder_2 = nn.LSTM(128, 128, 1) # output 1, N, 128\n",
    "\n",
    "        self.decoder_p = nn.LSTM(128, 256, 1) # input 30, N, 128 output 30, N, 256\n",
    "        self.decoder_p_2 = nn.LSTM(256, 256, 1) # input 30, N, 256 output 30, N, 256\n",
    "\n",
    "        self.decoder_v = nn.LSTM(128, 256,1) # input 30, N, 128 output 30, N, 256\n",
    "        self.decoder_v_2 = nn.LSTM(256, 256,1) # input 30, N, 256 output 30, N, 256\n",
    "\n",
    "        self.p_out = nn.Linear(256,128)\n",
    "        self.p_out_2 = nn.Linear(128,2)\n",
    "        self.v_out = nn.Linear(256,128)\n",
    "        self.v_out_2 = nn.Linear(128,2)\n",
    "\n",
    "    def forward(self, p, v):\n",
    "        batch = p.shape[0]\n",
    "        \n",
    "        x_p = self.p_in(p)\n",
    "        x_v = self.v_in(v)\n",
    "\n",
    "        x = torch.cat((x_p,x_v),dim=2)\n",
    "        x = x.permute(1,0,2)\n",
    "\n",
    "        x, _ = self.encoder(x)\n",
    "        _,(state_h,_) = self.encoder_2(x)\n",
    "\n",
    "        x = state_h.repeat(30,1,1)     \n",
    "\n",
    "        x_p,_ = self.decoder_p(x)\n",
    "        x_p,_ = self.decoder_p_2(x_p)\n",
    "\n",
    "        x_v,_ = self.decoder_v(x)\n",
    "        x_v,_ = self.decoder_v_2(x_v)\n",
    "\n",
    "        x_p = x_p.permute(1,0,2)\n",
    "        x_v = x_v.permute(1,0,2)\n",
    "\n",
    "        x_p = F.relu(self.p_out(x_p))\n",
    "        x_p = self.p_out_2(x_p)\n",
    "\n",
    "        x_v = F.relu(self.v_out(x_v))\n",
    "        x_v = self.v_out_2(x_v)\n",
    "\n",
    "\n",
    "        # batch 50, 345s per epoch\n",
    "        # p to p -> 9.21 after 10 epochs\n",
    "        # p + v to p -> 8.8 after 10 epochs\n",
    "        # p + v to p +v -> 6.65 after 10 epochs\n",
    "\n",
    "        # batch 100, 345s per epoch\n",
    "        # p + v to p +v -> 4.5 after 10 epochs\n",
    "\n",
    "        return x_p , x_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PFidR0mWBYc6"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "original network\n",
    "'''\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class Trajectory(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Trajectory, self).__init__()\n",
    "\n",
    "        self.p_in = nn.Linear(2,32) # N, 19, 2\n",
    "        self.v_in = nn.Linear(2,32) # N, 19, 2\n",
    "        \n",
    "        self.encoder = nn.LSTM(64, 64, 1) # input 19, N, 64 output 1, N, 64 \n",
    "\n",
    "        self.decoder_p = nn.LSTM(64, 128, 1) # input 30, N, 64 output 30, N, 128\n",
    "        self.decoder_v = nn.LSTM(64, 128,1) # input 30, N, 64 output 30, N, 128\n",
    "\n",
    "        self.p_out = nn.Linear(128,2)\n",
    "        self.v_out = nn.Linear(128,2)\n",
    "\n",
    "    def forward(self, p, v):\n",
    "        batch = p.shape[0]\n",
    "        x_p = self.p_in(p)\n",
    "        x_v = self.v_in(v)\n",
    "\n",
    "        x = torch.cat((x_p,x_v),dim=2)\n",
    "        x = x.permute(1,0,2)\n",
    "\n",
    "        _,(state_h,_) = self.encoder(x)\n",
    "\n",
    "        x = state_h.repeat(30,1,1).to(device)     \n",
    "\n",
    "        x_p,_ = self.decoder_p(x)\n",
    "        x_v,_ = self.decoder_v(x)\n",
    "\n",
    "        x_p = x_p.permute(1,0,2)\n",
    "        x_v = x_v.permute(1,0,2)\n",
    "\n",
    "        x_p = self.p_out(x_p)\n",
    "        x_v = self.v_out(x_v)\n",
    "\n",
    "        # batch 50, 345s per epoch\n",
    "        # p to p -> 9.21 after 10 epochs\n",
    "        # p + v to p -> 8.8 after 10 epochs\n",
    "        # p + v to p +v -> 6.65 after 10 epochs\n",
    "\n",
    "        # batch 100, 345s per epoch\n",
    "        # p + v to p +v -> 4.5 after 10 epochs\n",
    "\n",
    "        return x_p , x_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hkaCfzwse-L7"
   },
   "outputs": [],
   "source": [
    "# don't run\n",
    "\n",
    "import numpy as np\n",
    "model = Trajectory().double()\n",
    "print(model)\n",
    "\n",
    "p = np.zeros((4,19,2))\n",
    "v = np.zeros((4,19,2))\n",
    "p_torch = torch.tensor(p)\n",
    "v_torch = torch.tensor(v)\n",
    "\n",
    "output = model(p_torch,v_torch)\n",
    "print(len(output))\n",
    "print(output[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5-aPXOGJgnxo"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "batch_sz = 100\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_sz,\n",
    "    shuffle=False,\n",
    "    collate_fn=my_collate_train,\n",
    "    num_workers=2,\n",
    ")\n",
    "\n",
    "train_size = int(0.8 * len(train_loader.dataset))\n",
    "val_size = len(train_loader.dataset) - train_size\n",
    "train_data, val_data = torch.utils.data.random_split(\n",
    "    train_loader.dataset, [train_size, val_size]\n",
    ")\n",
    "\n",
    "print(\"\\nLENGTH OF TRAIN LOADER DATASET:\", len(train_loader.dataset))\n",
    "print(\"LENGTH OF TRAIN DATA:\", len(train_data), \"\\nLENGTH OF VAL DATA:\", len(val_data))\n",
    "\n",
    "train_data = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=batch_sz,\n",
    "    shuffle=False,\n",
    "    collate_fn=my_collate_train,\n",
    "    num_workers=2,\n",
    ")\n",
    "val_data = DataLoader(\n",
    "    val_data,\n",
    "    batch_size=batch_sz,\n",
    "    shuffle=False,\n",
    "    collate_fn=my_collate_train,\n",
    "    num_workers=2,\n",
    ")\n",
    "model = Trajectory().to(device)\n",
    "\n",
    "my_optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# decayRate = 0.999\n",
    "# my_lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=my_optim, gamma=decayRate)\n",
    "\n",
    "epoch = 20  # takes around 20 epochs to converge\n",
    "number = 1  # number of cars in each\n",
    "\n",
    "for i in range(epoch):\n",
    "\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    start = time.time()\n",
    "\n",
    "    train_loop = tqdm(enumerate(train_data), total=len(train_data))\n",
    "\n",
    "    for i_batch, sample_batch in train_loop:\n",
    "        inp, out = sample_batch\n",
    "        batch = inp.shape[0]\n",
    "\n",
    "        p_in = (\n",
    "            inp[:, 0].reshape(batch * number, 19, 2).to(device)\n",
    "        ) / 4800.0  # -2400.)/2400.\n",
    "        v_in = inp[:, 1].reshape(batch * number, 19, 2).to(device) / 100.0\n",
    "        p_out = (\n",
    "            out[:, 0].reshape(batch * number, 30, 2).to(device)\n",
    "        ) / 4800.0  # -2400.)/2400.\n",
    "        v_out = out[:, 1].reshape(batch * number, 30, 2).to(device) / 100.0\n",
    "\n",
    "        pred = model(p_in, v_in)\n",
    "\n",
    "        loss = 0\n",
    "        p_criteria = nn.MSELoss()\n",
    "        p_loss = torch.sqrt(p_criteria(pred[0], p_out))\n",
    "\n",
    "        v_criteria = nn.MSELoss()\n",
    "        v_loss = torch.sqrt(v_criteria(pred[1], v_out))\n",
    "\n",
    "        loss = p_loss + v_loss\n",
    "        epoch_loss += p_loss\n",
    "\n",
    "        my_optim.zero_grad()\n",
    "        loss.backward()\n",
    "        my_optim.step()\n",
    "\n",
    "        train_loop.set_description(f\"Train Epoch [{i + 1}/{epoch}]\")\n",
    "        train_loop.set_postfix(loss=epoch_loss.item())\n",
    "        # my_lr_scheduler.step()\n",
    "        # if(i>2999):\n",
    "        #   # print(pred[0]*2400.+2400., p_out[0]*2400.+2400.)\n",
    "        #   print(pred[0]*4800., p_out[0]*4800.)\n",
    "        # break\n",
    "    # print(\"Training Loss: \", i, epoch_loss.item(), time.time() - start)\n",
    "\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    val_loop = tqdm(enumerate(val_data), total=len(val_data))\n",
    "    for i_batch, sample_batch in val_loop:\n",
    "        inp, out = sample_batch\n",
    "        batch = inp.shape[0]\n",
    "\n",
    "        p_in = (inp[:, 0].reshape(batch * number, 19, 2).to(device)) / 4800.0\n",
    "        v_in = inp[:, 1].reshape(batch * number, 19, 2).to(device) / 100.0\n",
    "        p_out = (out[:, 0].reshape(batch * number, 30, 2).to(device)) / 4800.0\n",
    "        v_out = out[:, 1].reshape(batch * number, 30, 2).to(device) / 100.0\n",
    "\n",
    "        pred = model(p_in, v_in)\n",
    "\n",
    "        loss = 0\n",
    "        p_criteria = nn.MSELoss()\n",
    "        p_loss = torch.sqrt(p_criteria(pred[0], p_out))\n",
    "\n",
    "        epoch_loss += p_loss\n",
    "\n",
    "        val_loop.set_description(f\"Val.  Epoch [{i + 1}/{epoch}]\")\n",
    "        val_loop.set_postfix(loss=epoch_loss.item())\n",
    "    # print(\"Validation Loss: \", epoch_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "FdFKvwWzASi-"
   },
   "outputs": [],
   "source": [
    "def zeroNormNP(array, size=19, pos=np.array([-1, -1])):  # array is N,19,2\n",
    "    temp = []\n",
    "    if np.array_equal(pos, np.array([-1, -1])):\n",
    "        temp = array[:, 0]\n",
    "    else:\n",
    "        temp = pos  # should be N,2\n",
    "    temp = np.expand_dims(temp, 1)\n",
    "    temp = np.repeat(temp, size, 1)\n",
    "\n",
    "    return (array - temp) / 500.0, array[:, 0]\n",
    "\n",
    "\n",
    "def zeroNormTor(array, size=19, pos=torch.tensor([-1, -1])):  # array is N,19,2\n",
    "    temp = []\n",
    "    if np.array_equal(pos, torch.tensor([-1, -1])):\n",
    "        temp = array[:, 0]\n",
    "    else:\n",
    "        temp = pos  # should be N,2\n",
    "    temp = torch.unsqueeze(temp, 1)\n",
    "    temp = torch.repeat_interleave(temp, size, 1)\n",
    "    return (array - temp) / 500.0, array[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8wqSU86YvIgT"
   },
   "outputs": [],
   "source": [
    "# train on multiple cars per\n",
    "import time\n",
    "\n",
    "batch_sz = 100\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_sz,\n",
    "    shuffle=False,\n",
    "    collate_fn=my_collate_train_multiple,\n",
    "    num_workers=2,\n",
    ")\n",
    "\n",
    "train_size = int(0.8 * len(train_loader.dataset))\n",
    "val_size = len(train_loader.dataset) - train_size\n",
    "train_data, val_data = torch.utils.data.random_split(\n",
    "    train_loader.dataset, [train_size, val_size]\n",
    ")\n",
    "\n",
    "print(\"\\nLENGTH OF TRAIN LOADER DATASET:\", len(train_loader.dataset))\n",
    "print(\"LENGTH OF TRAIN DATA:\", len(train_data), \"\\nLENGTH OF VAL DATA:\", len(val_data))\n",
    "\n",
    "train_data = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=batch_sz,\n",
    "    shuffle=False,\n",
    "    collate_fn=my_collate_train_multiple,\n",
    "    num_workers=2,\n",
    ")\n",
    "val_data = DataLoader(\n",
    "    val_data,\n",
    "    batch_size=batch_sz,\n",
    "    shuffle=False,\n",
    "    collate_fn=my_collate_train_multiple,\n",
    "    num_workers=2,\n",
    ")\n",
    "model = Trajectory().to(device)\n",
    "\n",
    "my_optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# decayRate = 0.999\n",
    "# my_lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=my_optim, gamma=decayRate)\n",
    "\n",
    "epoch = 20  # takes around 20 epochs to converge\n",
    "number = 5  # number of cars in each\n",
    "\n",
    "best_val = 100\n",
    "\n",
    "for i in range(epoch):\n",
    "\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    start = time.time()\n",
    "\n",
    "    # train_loop = tqdm(enumerate(train_data), total=len(train_data))\n",
    "\n",
    "    for i_batch, sample_batch in enumerate(train_data):\n",
    "\n",
    "        inp, out = sample_batch\n",
    "        batch = inp.shape[1]\n",
    "\n",
    "        p_in, orig = zeroNormTor(inp[0].reshape(batch * number, 19, 2).to(device))\n",
    "        v_in = inp[1].reshape(batch * number, 19, 2).to(device) / 85.0\n",
    "        p_out, _ = zeroNormTor(\n",
    "            out[0].reshape(batch * number, 30, 2).to(device), 30, orig\n",
    "        )\n",
    "        v_out = out[1].reshape(batch * number, 30, 2).to(device) / 85.0\n",
    "\n",
    "        pred = model(p_in, v_in)\n",
    "\n",
    "        loss = 0\n",
    "        p_criteria = nn.MSELoss()\n",
    "        p_loss = torch.sqrt(p_criteria(pred[0], p_out))\n",
    "\n",
    "        v_criteria = nn.MSELoss()\n",
    "        v_loss = torch.sqrt(v_criteria(pred[1], v_out))\n",
    "\n",
    "        loss = p_loss + v_loss\n",
    "        epoch_loss += p_loss.item()\n",
    "\n",
    "        my_optim.zero_grad()\n",
    "        loss.backward()\n",
    "        my_optim.step()\n",
    "\n",
    "        # ur tqdm stuff broke\n",
    "        # train_loop.set_description(f\"Train Epoch [{i + 1}/{epoch}]\")\n",
    "        # train_loop.set_postfix(loss = epoch_loss.item())\n",
    "        # my_lr_scheduler.step()\n",
    "        # if(i>2999):\n",
    "        #   # print(pred[0]*2400.+2400., p_out[0]*2400.+2400.)\n",
    "        #   print(pred[0]*4800., p_out[0]*4800.)\n",
    "        # break\n",
    "    print(\"Training Loss: \", i, epoch_loss, time.time() - start)\n",
    "\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    # val_loop = tqdm(enumerate(val_data), total=len(val_data))\n",
    "    for i_batch, sample_batch in enumerate(val_data):\n",
    "        inp, out = sample_batch\n",
    "        batch = inp.shape[1]\n",
    "\n",
    "        p_in, orig = zeroNormTor(inp[0].reshape(batch * number, 19, 2).to(device))\n",
    "        v_in = inp[1].reshape(batch * number, 19, 2).to(device) / 85.0\n",
    "        p_out, _ = zeroNormTor(\n",
    "            out[0].reshape(batch * number, 30, 2).to(device), 30, orig\n",
    "        )\n",
    "        v_out = out[1].reshape(batch * number, 30, 2).to(device) / 85.0\n",
    "\n",
    "        pred = model(p_in, v_in)\n",
    "\n",
    "        loss = 0\n",
    "        p_criteria = nn.MSELoss()\n",
    "        p_loss = torch.sqrt(p_criteria(pred[0], p_out))\n",
    "\n",
    "        epoch_loss += p_loss.item()\n",
    "\n",
    "        # val_loop.set_description(f\"Val.  Epoch [{i + 1}/{epoch}]\")\n",
    "        # val_loop.set_postfix(loss = epoch_loss.item())\n",
    "    if epoch_loss < best_val:\n",
    "        filename = \"best.pth\"\n",
    "        state = {\n",
    "            \"epoch\": i,\n",
    "            \"state_dict\": model.state_dict(),\n",
    "            \"optimizer\": my_optim.state_dict(),\n",
    "        }\n",
    "        torch.save(state, filename)\n",
    "        print(\"saved\")\n",
    "        best_val = epoch_loss\n",
    "\n",
    "    print(\"Validation Loss: \", epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QjNAZOPL9cx2"
   },
   "outputs": [],
   "source": [
    "import time \n",
    "\n",
    "batch_sz = 100\n",
    "train_loader = DataLoader(train_dataset,batch_size=batch_sz, shuffle = False, collate_fn=my_collate_train, num_workers=2)\n",
    "\n",
    "model = Trajectory().to(device)\n",
    "\n",
    "my_optim = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# decayRate = 0.999\n",
    "# my_lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=my_optim, gamma=decayRate)\n",
    "\n",
    "epoch = 20 # takes around 20 epochs to converge\n",
    "number = 1 # number of cars in each \n",
    "\n",
    "for i in range(epoch):\n",
    "\n",
    "  model.train()\n",
    "  epoch_loss = 0\n",
    "  start = time.time()\n",
    "  for i_batch, sample_batch in enumerate(train_loader):\n",
    "    inp, out = sample_batch\n",
    "    batch = inp.shape[0]\n",
    "\n",
    "    p_in = (inp[:,0].reshape(batch*number,19,2).to(device))/4800. # -2400.)/2400.\n",
    "    v_in = inp[:,1].reshape(batch*number,19,2).to(device)/100.\n",
    "    p_out = (out[:,0].reshape(batch*number,30,2).to(device))/4800. # -2400.)/2400.\n",
    "    v_out = out[:,1].reshape(batch*number,30,2).to(device)/100.\n",
    "\n",
    "    pred = model(p_in, v_in)\n",
    "\n",
    "\n",
    "    loss = 0\n",
    "    p_criteria = nn.MSELoss()\n",
    "    p_loss = torch.sqrt(p_criteria(pred[0], p_out))\n",
    "\n",
    "    v_criteria = nn.MSELoss()\n",
    "    v_loss = torch.sqrt(v_criteria(pred[1], v_out))\n",
    "\n",
    "    loss = p_loss + v_loss\n",
    "    epoch_loss += p_loss\n",
    "\n",
    "    my_optim.zero_grad()\n",
    "    loss.backward()\n",
    "    my_optim.step()\n",
    "    # my_lr_scheduler.step()\n",
    "    # if(i>2999):\n",
    "    #   # print(pred[0]*2400.+2400., p_out[0]*2400.+2400.)\n",
    "    #   print(pred[0]*4800., p_out[0]*4800.)\n",
    "    # break\n",
    "  print(\"Training Loss: \", i, epoch_loss.item(), time.time() - start)\n",
    "  \n",
    "  model.eval()\n",
    "  epoch_loss = 0\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-uQ2Y3O0ELNN",
    "outputId": "1361d0f1-0251-47b7-e2ea-3baf07a6cfc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loaded checkpoint 'best.pth' (epoch 18)\n",
      "tensor([[3019.8669, 1598.0883],\n",
      "        [3015.8806, 1599.7953],\n",
      "        [3013.8967, 1599.0958],\n",
      "        [3013.3298, 1599.1573],\n",
      "        [3012.2002, 1598.6357],\n",
      "        [3011.4246, 1598.0896],\n",
      "        [3010.6511, 1597.4102],\n",
      "        [3009.8457, 1596.7095],\n",
      "        [3008.9858, 1596.0380],\n",
      "        [3008.1096, 1595.4120],\n",
      "        [3007.2500, 1594.8263],\n",
      "        [3006.4216, 1594.2684],\n",
      "        [3005.6260, 1593.7223],\n",
      "        [3004.8540, 1593.1758],\n",
      "        [3004.0947, 1592.6184],\n",
      "        [3003.3379, 1592.0452],\n",
      "        [3002.5745, 1591.4512],\n",
      "        [3001.7964, 1590.8369],\n",
      "        [3001.0027, 1590.2042],\n",
      "        [3000.1924, 1589.5566],\n",
      "        [2999.3674, 1588.9003],\n",
      "        [2998.5334, 1588.2437],\n",
      "        [2997.6995, 1587.5974],\n",
      "        [2996.8762, 1586.9738],\n",
      "        [2996.0767, 1586.3870],\n",
      "        [2995.3176, 1585.8522],\n",
      "        [2994.6140, 1585.3838],\n",
      "        [2993.9846, 1584.9976],\n",
      "        [2993.4458, 1584.7065],\n",
      "        [2993.0142, 1584.5221]], device='cuda:0', grad_fn=<MulBackward0>) tensor([[3028.0000, 1601.0000],\n",
      "        [3027.0000, 1601.0000],\n",
      "        [3026.0000, 1600.0000],\n",
      "        [3025.0002, 1599.0000],\n",
      "        [3024.0000, 1598.0000],\n",
      "        [3024.0000, 1598.0000],\n",
      "        [3023.0000, 1597.0000],\n",
      "        [3022.0000, 1597.0000],\n",
      "        [3021.0002, 1596.0000],\n",
      "        [3020.0000, 1595.0000],\n",
      "        [3019.0000, 1594.0000],\n",
      "        [3019.0000, 1594.0000],\n",
      "        [3018.0002, 1593.0000],\n",
      "        [3017.0002, 1592.0000],\n",
      "        [3016.0000, 1592.0000],\n",
      "        [3015.0000, 1591.0000],\n",
      "        [3014.0002, 1590.0000],\n",
      "        [3013.0002, 1589.0000],\n",
      "        [3012.0000, 1589.0000],\n",
      "        [3011.0000, 1588.0000],\n",
      "        [3010.0002, 1587.0000],\n",
      "        [3009.0002, 1586.0000],\n",
      "        [3009.0002, 1585.0000],\n",
      "        [3008.0000, 1585.0000],\n",
      "        [3007.0000, 1584.0001],\n",
      "        [3006.0002, 1583.0000],\n",
      "        [3005.0002, 1582.0001],\n",
      "        [3004.0000, 1581.0000],\n",
      "        [3003.0000, 1580.0001],\n",
      "        [3002.0002, 1580.0001]], device='cuda:0')\n",
      "Validation Loss:  0.0016427765367552638\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "load = True \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "initial = 0\n",
    "\n",
    "model.eval()\n",
    "\n",
    "if(load):\n",
    "  checkpoint = torch.load('best.pth')\n",
    "  model.load_state_dict(checkpoint['state_dict'])\n",
    "  optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "  print(\"=> loaded checkpoint '{}' (epoch {})\".format(filename, checkpoint['epoch']))\n",
    "  initial += int(checkpoint['epoch'])\n",
    "\n",
    "batch_sz = 100\n",
    "train_loader = DataLoader(train_dataset,batch_size=batch_sz, shuffle = False, collate_fn=my_collate_train_multiple, num_workers=2)\n",
    "\n",
    "epoch_loss =0\n",
    "batch = 60\n",
    "number = 5\n",
    "\n",
    "for i_batch, sample_batch in enumerate(train_loader):\n",
    "  inp, out = sample_batch\n",
    "  batch = inp.shape[1]\n",
    "\n",
    "  p_in = (inp[0].reshape(batch*number,19,2).to(device))/4800.\n",
    "  v_in = (inp[1].reshape(batch*number,19,2).to(device)+85.)/170.\n",
    "  p_out = (out[0].reshape(batch*number,30,2).to(device))/4800.\n",
    "  v_out = (out[1].reshape(batch*number,30,2).to(device)+85.)/170.\n",
    "\n",
    "  pred = model(p_in, v_in)\n",
    "  loss = 0\n",
    "  p_criteria = nn.MSELoss()\n",
    "  p_loss = torch.sqrt(p_criteria(pred[0], p_out))\n",
    "\n",
    "  epoch_loss += p_loss.item()\n",
    "  print(pred[0][10]*4800., p_out[10]*4800.)\n",
    "  break\n",
    "  \n",
    "print(\"Validation Loss: \", epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QhL6nFx1q3bm",
    "outputId": "f465a863-9665-4984-9d88-51355d8168fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loaded checkpoint 'best.pth' (epoch 18)\n"
     ]
    }
   ],
   "source": [
    "import csv \n",
    "load = True \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "initial = 0\n",
    "\n",
    "model.eval()\n",
    "\n",
    "if(load):\n",
    "  checkpoint = torch.load('best.pth')\n",
    "  model.load_state_dict(checkpoint['state_dict'])\n",
    "  optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "  print(\"=> loaded checkpoint '{}' (epoch {})\".format(filename, checkpoint['epoch']))\n",
    "  initial += int(checkpoint['epoch'])\n",
    "\n",
    "\n",
    "temp = []\n",
    "\n",
    "new_path = \"/content/new_val_in\"\n",
    "val_dataset  = ArgoverseDataset(data_path=new_path)\n",
    "\n",
    "top = []\n",
    "top.append(\"ID\")\n",
    "for i in range(60):\n",
    "  top.append(\"v\"+str(i+1))\n",
    "temp.append(top)\n",
    "\n",
    "batch = 60\n",
    "number = 1\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in val_dataset:\n",
    "      row = []\n",
    "      scene = i['scene_idx']\n",
    "      agent = i['agent_id']\n",
    "      target =0\n",
    "      for x in range(len(i['track_id'])):\n",
    "        if i['track_id'][x][0] == agent:\n",
    "          target = x\n",
    "\n",
    "      p_in = torch.LongTensor(i['p_in'])\n",
    "      v_in = torch.LongTensor(i['v_in'])\n",
    "\n",
    "      p_in = (p_in.reshape(batch*number,19,2).to(device))/4800.\n",
    "      v_in = (v_in.reshape(batch*number,19,2).to(device)+85.)/170.\n",
    "\n",
    "      pred = model(p_in, v_in)\n",
    "\n",
    "      pred_out = pred[0]*4800.\n",
    "      \n",
    "      output = pred_out[target]\n",
    "\n",
    "      row.append(scene)\n",
    "      row = row + torch.flatten(output).cpu().detach().numpy().tolist()\n",
    "      temp.append(row)\n",
    "\n",
    "with open('submission4.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(temp)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "151B_Kaggle_Comp",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
