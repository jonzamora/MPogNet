{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "151B_Kaggle_Comp",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxVcyAsPWKYo",
        "outputId": "49867faa-57cb-41d3-a0c7-759d0c737d43"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.activity.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fexperimentsandconfigs%20https%3a%2f%2fwww.googleapis.com%2fauth%2fphotos.native&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "4/1AY0e-g7NNKmNQtyUlTXjM15ho-v34Bt-d7WR-PTU49-5AIYcSTRjwi0k6JI\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "h7XQ4vP9YwDh"
      },
      "source": [
        "!yes | unzip /content/gdrive/MyDrive/151B_data/new_train.zip > /dev/null\n",
        "!yes | unzip /content/gdrive/MyDrive/151B_data/new_val_in.zip > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Bz7A-XhOQ8L4"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import os, os.path \n",
        "import numpy \n",
        "import pickle\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "\"\"\"Change to the data folder\"\"\"\n",
        "new_path = \"/content/new_train\"\n",
        "\n",
        "# number of sequences in each dataset\n",
        "# train:205942  val:3200 test: 36272 \n",
        "# sequences sampled at 10HZ rate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "B6bHeDoMQ-y7"
      },
      "source": [
        "class ArgoverseDataset(Dataset):\n",
        "    \"\"\"Dataset class for Argoverse\"\"\"\n",
        "    def __init__(self, data_path: str, transform=None):\n",
        "        super(ArgoverseDataset, self).__init__()\n",
        "        self.data_path = data_path\n",
        "        self.transform = transform\n",
        "\n",
        "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
        "        self.pkl_list.sort()\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.pkl_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        pkl_path = self.pkl_list[idx]\n",
        "        with open(pkl_path, 'rb') as f:\n",
        "            data = pickle.load(f)\n",
        "            \n",
        "        if self.transform:\n",
        "            data = self.transform(data)\n",
        "\n",
        "        return data\n",
        "\n",
        "\n",
        "# intialize a dataset\n",
        "train_dataset  = ArgoverseDataset(data_path=new_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "s33LYX3DREUh"
      },
      "source": [
        "batch_sz = 100\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def my_collate_train(batch):\n",
        "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
        "\n",
        "    batch_inp = []\n",
        "    batch_out = []\n",
        "\n",
        "    for scene in batch:\n",
        "      agent = scene['agent_id']\n",
        "      target = 0\n",
        "      for x in range(len(scene['track_id'])):\n",
        "        if scene['track_id'][x][0] == agent:\n",
        "          target = x\n",
        "      inp = [scene['p_in'][target], scene['v_in'][target]]\n",
        "      out = [scene['p_out'][target], scene['v_out'][target]]\n",
        "      batch_inp.append(inp)\n",
        "      batch_out.append(out)\n",
        "\n",
        "    # scene level #####################\n",
        "    # batch_inp = []\n",
        "    # batch_out = []\n",
        "    # for scene in batch:\n",
        "    #   mask = scene['car_mask'].flatten()==1\n",
        "    #   # print(np.count_nonzero(mask))\n",
        "    #   inp = [scene['p_in'][mask], scene['v_in'][mask]]\n",
        "    #   out = [scene['p_out'][mask], scene['v_out'][mask]]\n",
        "    #   batch_inp.append(inp)\n",
        "    #   batch_out.append(out)\n",
        "    ####################################\n",
        "\n",
        "\n",
        "    inp = torch.LongTensor(batch_inp)\n",
        "    out = torch.LongTensor(batch_out)\n",
        "    return [inp, out]\n",
        "\n",
        "def my_collate_train_multiple(batch):\n",
        "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
        "\n",
        "    batch_inp = []\n",
        "    batch_out = []\n",
        "\n",
        "    for scene in batch:\n",
        "      agent = scene['agent_id']\n",
        "      target = 0\n",
        "      for x in range(len(scene['track_id'])):\n",
        "        if scene['track_id'][x][0] == agent:\n",
        "          target = x\n",
        "      inp = [scene['p_in'][target], scene['v_in'][target]]\n",
        "      out = [scene['p_out'][target], scene['v_out'][target]]\n",
        "\n",
        "      other_in = np.zeros((5,2,19,2)) # need to permute to 2,5,19,2 later\n",
        "      other_out = np.zeros((5,2,30,2))\n",
        "\n",
        "      other_in[0] = inp\n",
        "      other_out[0] = out\n",
        "\n",
        "      mask = scene['car_mask'].flatten()==1\n",
        "      mask = np.delete(mask,target)\n",
        "      mask = np.where(mask == True)[0]\n",
        "\n",
        "      if(len(mask)>=4):\n",
        "        temp = random.sample(mask.tolist(),4)\n",
        "        for i in range(len(temp)):\n",
        "          other_in[i+1] = [scene['p_in'][temp[i]], scene['v_in'][temp[i]]]\n",
        "          other_out[i+1] = [scene['p_out'][temp[i]], scene['v_out'][temp[i]]]\n",
        "      else:\n",
        "        for i in range(len(mask)):\n",
        "          other_in[i+1] = [scene['p_in'][mask[i]], scene['v_in'][mask[i]]]\n",
        "          other_out[i+1] = [scene['p_out'][mask[i]], scene['v_out'][mask[i]]]\n",
        "        for i in range(4-len(mask)):\n",
        "          other_in[i+1+len(mask)] = inp\n",
        "          other_out[i+1+len(mask)] = out\n",
        "\n",
        "      batch_inp.append(other_in.tolist())\n",
        "      batch_out.append(other_out.tolist())\n",
        "\n",
        "    # scene level #####################\n",
        "    # batch_inp = []\n",
        "    # batch_out = []\n",
        "    # for scene in batch:\n",
        "    #   mask = scene['car_mask'].flatten()==1\n",
        "    #   # print(np.count_nonzero(mask))\n",
        "    #   inp = [scene['p_in'][mask], scene['v_in'][mask]]\n",
        "    #   out = [scene['p_out'][mask], scene['v_out'][mask]]\n",
        "    #   batch_inp.append(inp)\n",
        "    #   batch_out.append(out)\n",
        "    ####################################\n",
        "\n",
        "\n",
        "    inp = torch.LongTensor(batch_inp)\n",
        "    inp = inp.permute(2,0,1,3,4) # p/v, batch, cars, points, x/y\n",
        "    out = torch.LongTensor(batch_out)\n",
        "    out = out.permute(2,0,1,3,4) \n",
        "    return [inp, out]\n",
        "\n",
        "def my_collate_val(batch):\n",
        "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
        "\n",
        "    inp = [[scene['p_in'], scene['v_in']] for scene in batch]\n",
        "    mask = [scene['car_mask'] for scene in batch]\n",
        "\n",
        "    inp = torch.LongTensor(inp)\n",
        "    mask = torch.LongTensor(mask)\n",
        "    return [inp, mask]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elKNcVDyEUOo"
      },
      "source": [
        "# don't run\n",
        "\n",
        "train_loader = DataLoader(train_dataset,batch_size=batch_sz, shuffle = False, collate_fn=my_collate_train_multiple, num_workers=2)\n",
        "\n",
        "# max_p_x = 0\n",
        "# min_p_x = 5000\n",
        "# max_p_y = 0\n",
        "# min_p_y = 5000\n",
        "# max_v_x = 0\n",
        "# min_v_x = 100\n",
        "# max_v_y = 0\n",
        "# min_v_y = 100\n",
        "\n",
        "# for i_batch, sample_batch in enumerate(train_loader):\n",
        "#     inp, out = sample_batch\n",
        "#     for i in inp:\n",
        "#       if i[0][:,0].max()> max_p_x:\n",
        "#         max_p_x = i[0][:,0].max()\n",
        "#       if i[0][:,0].min() < min_p_x:\n",
        "#         min_p_x = i[0][:,0].min()\n",
        "#       if i[0][:,1].max()> max_p_y:\n",
        "#         max_p_y = i[0][:,1].max()\n",
        "#       if i[0][:,1].min() < min_p_y:\n",
        "#         min_p_y = i[0][:,1].min()\n",
        "\n",
        "#       if i[1][:,0].max()> max_v_x:\n",
        "#         max_v_x = i[1][:,0].max()\n",
        "#       if i[1][:,0].min()< min_v_x:\n",
        "#         min_v_x = i[1][:,0].min()\n",
        "#       if i[1][:,1].max()> max_v_y:\n",
        "#         max_v_y = i[1][:,1].max()\n",
        "#       if i[1][:,1].min()< min_v_y:\n",
        "#         min_v_y = i[1][:,1].min()\n",
        "\n",
        "#     for o in out:\n",
        "#       if o[0][:,0].max()> max_p_x:\n",
        "#         max_p_x = o[0][:,0].max()\n",
        "#       if o[0][:,0].min() < min_p_x:\n",
        "#         min_p_x = o[0][:,0].min()\n",
        "#       if o[0][:,1].max()> max_p_y:\n",
        "#         max_p_y = o[0][:,1].max()\n",
        "#       if o[0][:,1].min() < min_p_y:\n",
        "#         min_p_y = o[0][:,1].min()\n",
        "\n",
        "#       if o[1][:,0].max()> max_v_x:\n",
        "#         max_v_x = o[1][:,0].max()\n",
        "#       if o[1][:,0].min()< min_v_x:\n",
        "#         min_v_x = o[1][:,0].min()\n",
        "#       if o[1][:,1].max()> max_v_y:\n",
        "#         max_v_y = o[1][:,1].max()\n",
        "#       if o[1][:,1].min()< min_v_y:\n",
        "#         min_v_y = o[1][:,1].min()\n",
        "\n",
        "#     if(i_batch%100==0):\n",
        "#       print(i_batch)\n",
        "\n",
        "max = 0\n",
        "min = 1000\n",
        "factor = 0\n",
        "\n",
        "for i_batch, sample_batch in enumerate(train_loader):\n",
        "    inp, out = sample_batch\n",
        "        \n",
        "    for i in range(len(inp[0])):\n",
        "      for c in range(len(inp[0][i])):\n",
        "        disp = torch.unsqueeze(inp[0][i][c][0],0)\n",
        "        x = torch.repeat_interleave(disp,19,0)\n",
        "        displacement_in = torch.max(torch.abs(inp[0][i][c] - x))\n",
        "\n",
        "        if(torch.min(inp[0][i][c] - x)<min):\n",
        "          min = torch.min(inp[0][i][c] - x)\n",
        "\n",
        "        if(torch.max(inp[0][i][c] - x)>max):\n",
        "          max = torch.max(inp[0][i][c] - x)  \n",
        "\n",
        "        x = torch.repeat_interleave(disp,30,0)\n",
        "        displacement_out = torch.max(torch.abs(out[0][i][c] - x))\n",
        "\n",
        "        if(torch.min(out[0][i][c] - x)<min):\n",
        "          min = torch.min(out[0][i][c] - x)\n",
        "\n",
        "        if(torch.max(out[0][i][c] - x)>max):\n",
        "          max = torch.max(out[0][i][c] - x)  \n",
        "\n",
        "        if(displacement_in!=0):\n",
        "          temp = displacement_out/displacement_in\n",
        "          if(temp>factor):\n",
        "            factor = temp\n",
        "    if(i_batch%100==0):\n",
        "      print(i_batch, factor, max, min)\n",
        "# print(max_p_x, min_p_x, max_p_y, min_p_y) # [4800,-50,4800,-50]\n",
        "# print(max_v_x, min_v_x, max_v_y, min_v_y) # [200,-200,200,-200]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7YyLqs1q2_S"
      },
      "source": [
        "'''\n",
        "start with initial 19 points and zero fill remaining\n",
        "'''\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class Trajectory(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Trajectory, self).__init__()\n",
        "\n",
        "        self.p_in = nn.Linear(2,64) # N, 19, 2\n",
        "        self.v_in = nn.Linear(2,64) # N, 19, 2\n",
        "        \n",
        "        self.encoder = nn.LSTM(128, 128, 1) # input 19, N, 64 output 1, N, 64 \n",
        "\n",
        "        self.decoder_p = nn.LSTM(128, 128, 1) # input 30, N, 64 output 30, N, 64\n",
        "        self.decoder_v = nn.LSTM(128, 128,1) # input 30, N, 64 output 30, N, 64\n",
        "\n",
        "        self.p_out = nn.Linear(128,2)\n",
        "        self.v_out = nn.Linear(128,2)\n",
        "\n",
        "    def forward(self, p, v):\n",
        "        batch = p.shape[0]\n",
        "        x_p = self.p_in(p)\n",
        "        x_v = self.v_in(v)\n",
        "\n",
        "        x = torch.cat((x_p,x_v),dim=2)\n",
        "        x = x.permute(1,0,2)\n",
        "\n",
        "        _,(state_h) = self.encoder(x)\n",
        "\n",
        "        temp = torch.zeros(11,batch,128).to(device)\n",
        "        x = torch.cat((x,temp),dim=0)\n",
        "\n",
        "        x_p,_ = self.decoder_p(x,state_h)\n",
        "        x_v,_ = self.decoder_v(x,state_h)\n",
        "\n",
        "        x_p = x_p.permute(1,0,2)\n",
        "        x_v = x_v.permute(1,0,2)\n",
        "\n",
        "        x_p = self.p_out(x_p)\n",
        "        x_v = self.v_out(x_v)\n",
        "\n",
        "        # batch 50, 345s per epoch\n",
        "        # p to p -> 9.21 after 10 epochs\n",
        "        # p + v to p -> 8.8 after 10 epochs\n",
        "        # p + v to p +v -> 6.65 after 10 epochs\n",
        "\n",
        "        # batch 100, 345s per epoch\n",
        "        # p + v to p +v -> 4.5 after 10 epochs\n",
        "\n",
        "        return x_p , x_v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntQ3tQcSA8Vz"
      },
      "source": [
        "'''\n",
        "start with initial 19 points and zero fill remaining, bigger\n",
        "'''\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class Trajectory(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Trajectory, self).__init__()\n",
        "\n",
        "        self.p_in = nn.Linear(2,64) # N, 19, 2\n",
        "        self.v_in = nn.Linear(2,64) # N, 19, 2\n",
        "        \n",
        "        self.convert = nn.Linear(128,256)\n",
        "\n",
        "        self.encoder = nn.LSTM(128,256,1)\n",
        "        self.encoder_2 = nn.LSTM(256, 256, 1) # input 19, N, 256 output 1, N, 256\n",
        "\n",
        "        self.decoder_p = nn.LSTM(256, 256, 1) \n",
        "        self.decoder_p_2 = nn.LSTM(256, 512, 1) \n",
        "\n",
        "        self.decoder_v = nn.LSTM(256, 256,1) \n",
        "        self.decoder_v_2 = nn.LSTM(256, 512,1) \n",
        "\n",
        "        self.p_out = nn.Linear(512,256)\n",
        "        self.p_out_2 = nn.Linear(256,2)\n",
        "        self.v_out = nn.Linear(512,256)\n",
        "        self.v_out_2 = nn.Linear(256,2)\n",
        "\n",
        "\n",
        "    def forward(self, p, v):\n",
        "        batch = p.shape[0]\n",
        "        x_p = self.p_in(p)\n",
        "        x_v = self.v_in(v)\n",
        "\n",
        "        x = torch.cat((x_p,x_v),dim=2)\n",
        "        x = x.permute(1,0,2)\n",
        "\n",
        "        x_temp,_ = self.encoder(x)\n",
        "        _,(state_h) = self.encoder_2(x_temp)\n",
        "\n",
        "        temp = torch.zeros(11,batch,128).to(device)\n",
        "\n",
        "        x = torch.cat((x,temp),dim=0)\n",
        "\n",
        "        x = self.convert(x)\n",
        "\n",
        "        x_p,_ = self.decoder_p(x,state_h)\n",
        "        x_p,_ = self.decoder_p_2(x_p)\n",
        "\n",
        "        x_v,_ = self.decoder_v(x,state_h)\n",
        "        x_v,_ = self.decoder_v_2(x_v)\n",
        "\n",
        "        x_p = x_p.permute(1,0,2)\n",
        "        x_v = x_v.permute(1,0,2)\n",
        "\n",
        "        x_p = F.relu(self.p_out(x_p))\n",
        "        x_p = self.p_out_2(x_p)\n",
        "\n",
        "        x_v = F.relu(self.v_out(x_v))\n",
        "        x_v = self.v_out_2(x_v)\n",
        "\n",
        "\n",
        "        # batch 50, 345s per epoch\n",
        "        # p to p -> 9.21 after 10 epochs\n",
        "        # p + v to p -> 8.8 after 10 epochs\n",
        "        # p + v to p +v -> 6.65 after 10 epochs\n",
        "\n",
        "        # batch 100, 345s per epoch\n",
        "        # p + v to p +v -> 4.5 after 10 epochs\n",
        "\n",
        "        return x_p , x_v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_ENkqUjWfkn"
      },
      "source": [
        "'''\n",
        "Edward's Tests, bigger\n",
        "'''\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class Trajectory(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Trajectory, self).__init__()\n",
        "\n",
        "        self.p_in = nn.Linear(2,32) # N, 19, 2\n",
        "        self.v_in = nn.Linear(2,32) # N, 19, 2\n",
        "        \n",
        "        self.encoder = nn.LSTM(64, 128, 1) # input 19, N, 64 output 19, N, 128\n",
        "        self.encoder_2 = nn.LSTM(128, 128, 1) # output 1, N, 128\n",
        "\n",
        "        self.decoder_p = nn.LSTM(128, 256, 1) # input 30, N, 128 output 30, N, 256\n",
        "        self.decoder_p_2 = nn.LSTM(256, 256, 1) # input 30, N, 256 output 30, N, 256\n",
        "\n",
        "        self.decoder_v = nn.LSTM(128, 256,1) # input 30, N, 128 output 30, N, 256\n",
        "        self.decoder_v_2 = nn.LSTM(256, 256,1) # input 30, N, 256 output 30, N, 256\n",
        "\n",
        "        self.p_out = nn.Linear(256,128)\n",
        "        self.p_out_2 = nn.Linear(128,2)\n",
        "        self.v_out = nn.Linear(256,128)\n",
        "        self.v_out_2 = nn.Linear(128,2)\n",
        "\n",
        "    def forward(self, p, v):\n",
        "        batch = p.shape[0]\n",
        "        \n",
        "        x_p = self.p_in(p)\n",
        "        x_v = self.v_in(v)\n",
        "\n",
        "        x = torch.cat((x_p,x_v),dim=2)\n",
        "        x = x.permute(1,0,2)\n",
        "\n",
        "        x, _ = self.encoder(x)\n",
        "        _,(state_h,_) = self.encoder_2(x)\n",
        "\n",
        "        x = state_h.repeat(30,1,1)     \n",
        "\n",
        "        x_p,_ = self.decoder_p(x)\n",
        "        x_p,_ = self.decoder_p_2(x_p)\n",
        "\n",
        "        x_v,_ = self.decoder_v(x)\n",
        "        x_v,_ = self.decoder_v_2(x_v)\n",
        "\n",
        "        x_p = x_p.permute(1,0,2)\n",
        "        x_v = x_v.permute(1,0,2)\n",
        "\n",
        "        x_p = F.relu(self.p_out(x_p))\n",
        "        x_p = self.p_out_2(x_p)\n",
        "\n",
        "        x_v = F.relu(self.v_out(x_v))\n",
        "        x_v = self.v_out_2(x_v)\n",
        "\n",
        "\n",
        "        # batch 50, 345s per epoch\n",
        "        # p to p -> 9.21 after 10 epochs\n",
        "        # p + v to p -> 8.8 after 10 epochs\n",
        "        # p + v to p +v -> 6.65 after 10 epochs\n",
        "\n",
        "        # batch 100, 345s per epoch\n",
        "        # p + v to p +v -> 4.5 after 10 epochs\n",
        "\n",
        "        return x_p , x_v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5McUfwqBvdc"
      },
      "source": [
        "'''\n",
        "Edward's Tests, bigger, bigger (not as good)\n",
        "'''\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class Trajectory(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Trajectory, self).__init__()\n",
        "\n",
        "        self.p_in = nn.Linear(2,32) # N, 19, 2\n",
        "        self.v_in = nn.Linear(2,32) # N, 19, 2\n",
        "        \n",
        "        self.encoder = nn.LSTM(64, 128, 1) # input 19, N, 64 output 19, N, 128\n",
        "        self.encoder_2 = nn.LSTM(128, 128, 1) # output 1, N, 128\n",
        "\n",
        "        self.translate = nn.Linear(128,256) # translation\n",
        "\n",
        "        self.decoder_p = nn.LSTM(256, 512, 1) # input 30, N, 128 output 30, N, 256\n",
        "        self.decoder_p_2 = nn.LSTM(512,512, 1) # input 30, N, 256 output 30, N, 256\n",
        "\n",
        "        self.decoder_v = nn.LSTM(256, 512,1) # input 30, N, 128 output 30, N, 256\n",
        "        self.decoder_v_2 = nn.LSTM(512, 512,1) # input 30, N, 256 output 30, N, 256\n",
        "\n",
        "        self.p_out = nn.Linear(512,256)\n",
        "        self.p_out_2 = nn.Linear(256,2)\n",
        "        self.v_out = nn.Linear(512,256)\n",
        "        self.v_out_2 = nn.Linear(256,2)\n",
        "\n",
        "    def forward(self, p, v):\n",
        "        batch = p.shape[0]\n",
        "        \n",
        "        x_p = self.p_in(p)\n",
        "        x_v = self.v_in(v)\n",
        "\n",
        "        x = torch.cat((x_p,x_v),dim=2)\n",
        "        x = x.permute(1,0,2)\n",
        "\n",
        "        x, _ = self.encoder(x)\n",
        "        _,(state_h,_) = self.encoder_2(x)\n",
        "\n",
        "        state_h = self.translate(state_h)\n",
        "\n",
        "        x = state_h.repeat(30,1,1)     \n",
        "\n",
        "        x_p,_ = self.decoder_p(x)\n",
        "        x_p,_ = self.decoder_p_2(x_p)\n",
        "\n",
        "        x_v,_ = self.decoder_v(x)\n",
        "        x_v,_ = self.decoder_v_2(x_v)\n",
        "\n",
        "        x_p = x_p.permute(1,0,2)\n",
        "        x_v = x_v.permute(1,0,2)\n",
        "\n",
        "        x_p = F.relu(self.p_out(x_p))\n",
        "        x_p = self.p_out_2(x_p)\n",
        "\n",
        "        x_v = F.relu(self.v_out(x_v))\n",
        "        x_v = self.v_out_2(x_v)\n",
        "\n",
        "\n",
        "        # batch 50, 345s per epoch\n",
        "        # p to p -> 9.21 after 10 epochs\n",
        "        # p + v to p -> 8.8 after 10 epochs\n",
        "        # p + v to p +v -> 6.65 after 10 epochs\n",
        "\n",
        "        # batch 100, 345s per epoch\n",
        "        # p + v to p +v -> 4.5 after 10 epochs\n",
        "\n",
        "        return x_p , x_v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFidR0mWBYc6"
      },
      "source": [
        "'''\n",
        "original network\n",
        "'''\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class Trajectory(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Trajectory, self).__init__()\n",
        "\n",
        "        self.p_in = nn.Linear(2,32) # N, 19, 2\n",
        "        self.v_in = nn.Linear(2,32) # N, 19, 2\n",
        "        \n",
        "        self.encoder = nn.LSTM(64, 64, 1) # input 19, N, 64 output 1, N, 64 \n",
        "\n",
        "        self.decoder_p = nn.LSTM(64, 128, 1) # input 30, N, 64 output 30, N, 128\n",
        "        self.decoder_v = nn.LSTM(64, 128,1) # input 30, N, 64 output 30, N, 128\n",
        "\n",
        "        self.p_out = nn.Linear(128,2)\n",
        "        self.v_out = nn.Linear(128,2)\n",
        "\n",
        "    def forward(self, p, v):\n",
        "        batch = p.shape[0]\n",
        "        x_p = self.p_in(p)\n",
        "        x_v = self.v_in(v)\n",
        "\n",
        "        x = torch.cat((x_p,x_v),dim=2)\n",
        "        x = x.permute(1,0,2)\n",
        "\n",
        "        _,(state_h,_) = self.encoder(x)\n",
        "\n",
        "        x = state_h.repeat(30,1,1).to(device)     \n",
        "\n",
        "        x_p,_ = self.decoder_p(x)\n",
        "        x_v,_ = self.decoder_v(x)\n",
        "\n",
        "        x_p = x_p.permute(1,0,2)\n",
        "        x_v = x_v.permute(1,0,2)\n",
        "\n",
        "        x_p = self.p_out(x_p)\n",
        "        x_v = self.v_out(x_v)\n",
        "\n",
        "        # batch 50, 345s per epoch\n",
        "        # p to p -> 9.21 after 10 epochs\n",
        "        # p + v to p -> 8.8 after 10 epochs\n",
        "        # p + v to p +v -> 6.65 after 10 epochs\n",
        "\n",
        "        # batch 100, 345s per epoch\n",
        "        # p + v to p +v -> 4.5 after 10 epochs\n",
        "\n",
        "        return x_p , x_v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkaCfzwse-L7",
        "outputId": "d447e14a-4159-4f5f-aec7-f01f78fb91f5"
      },
      "source": [
        "# don't run\n",
        "\n",
        "import numpy as np\n",
        "model = Trajectory().double().to(device)\n",
        "print(model)\n",
        "\n",
        "p = np.zeros((4,19,2))\n",
        "v = np.zeros((4,19,2))\n",
        "p_torch = torch.tensor(p).to(device)\n",
        "v_torch = torch.tensor(v).to(device)\n",
        "\n",
        "output = model(p_torch,v_torch)\n",
        "print(len(output))\n",
        "print(output[0].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trajectory(\n",
            "  (p_in): Linear(in_features=2, out_features=64, bias=True)\n",
            "  (v_in): Linear(in_features=2, out_features=64, bias=True)\n",
            "  (convert): Linear(in_features=128, out_features=256, bias=True)\n",
            "  (encoder): LSTM(128, 256)\n",
            "  (encoder_2): LSTM(256, 256)\n",
            "  (decoder_p): LSTM(256, 256)\n",
            "  (decoder_p_2): LSTM(256, 512)\n",
            "  (decoder_v): LSTM(256, 256)\n",
            "  (decoder_v_2): LSTM(256, 512)\n",
            "  (p_out): Linear(in_features=512, out_features=256, bias=True)\n",
            "  (p_out_2): Linear(in_features=256, out_features=2, bias=True)\n",
            "  (v_out): Linear(in_features=512, out_features=256, bias=True)\n",
            "  (v_out_2): Linear(in_features=256, out_features=2, bias=True)\n",
            ")\n",
            "2\n",
            "torch.Size([4, 30, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-aPXOGJgnxo"
      },
      "source": [
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "batch_sz = 100\n",
        "train_loader = DataLoader(train_dataset,batch_size=batch_sz, shuffle = False, collate_fn=my_collate_train, num_workers=2)\n",
        "\n",
        "train_size = int(0.8 * len(train_loader.dataset))\n",
        "val_size = len(train_loader.dataset) - train_size\n",
        "train_data, val_data = torch.utils.data.random_split(train_loader.dataset, [train_size, val_size])\n",
        "\n",
        "print(\"\\nLENGTH OF TRAIN LOADER DATASET:\", len(train_loader.dataset))\n",
        "print(\"LENGTH OF TRAIN DATA:\", len(train_data), \"\\nLENGTH OF VAL DATA:\", len(val_data))\n",
        "\n",
        "train_data = DataLoader(train_data, batch_size=batch_sz, shuffle = False, collate_fn=my_collate_train, num_workers=2)\n",
        "val_data = DataLoader(val_data, batch_size=batch_sz, shuffle = False, collate_fn=my_collate_train, num_workers=2)\n",
        "model = Trajectory().to(device)\n",
        "\n",
        "my_optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# decayRate = 0.999    \n",
        "# my_lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=my_optim, gamma=decayRate)\n",
        "\n",
        "epoch = 20 # takes around 20 epochs to converge\n",
        "number = 1 # number of cars in each \n",
        "\n",
        "for i in range(epoch):\n",
        "\n",
        "  model.train()\n",
        "  epoch_loss = 0\n",
        "  start = time.time()\n",
        "  \n",
        "  train_loop = tqdm(enumerate(train_data), total=len(train_data))\n",
        "\n",
        "  for i_batch, sample_batch in train_loop:\n",
        "    inp, out = sample_batch\n",
        "    batch = inp.shape[0]\n",
        "\n",
        "    p_in = (inp[:,0].reshape(batch*number,19,2).to(device))/4800. # -2400.)/2400.\n",
        "    v_in = inp[:,1].reshape(batch*number,19,2).to(device)/100.\n",
        "    p_out = (out[:,0].reshape(batch*number,30,2).to(device))/4800. # -2400.)/2400.\n",
        "    v_out = out[:,1].reshape(batch*number,30,2).to(device)/100.\n",
        "\n",
        "    pred = model(p_in, v_in)\n",
        "\n",
        "\n",
        "    loss = 0\n",
        "    p_criteria = nn.MSELoss()\n",
        "    p_loss = torch.sqrt(p_criteria(pred[0], p_out))\n",
        "\n",
        "    v_criteria = nn.MSELoss()\n",
        "    v_loss = torch.sqrt(v_criteria(pred[1], v_out))\n",
        "\n",
        "    loss = p_loss + v_loss\n",
        "    epoch_loss += p_loss\n",
        "\n",
        "    my_optim.zero_grad()\n",
        "    loss.backward()\n",
        "    my_optim.step()\n",
        "\n",
        "    train_loop.set_description(f\"Train Epoch [{i + 1}/{epoch}]\")\n",
        "    train_loop.set_postfix(loss = epoch_loss.item())\n",
        "    # my_lr_scheduler.step()\n",
        "    # if(i>2999):\n",
        "    #   # print(pred[0]*2400.+2400., p_out[0]*2400.+2400.)\n",
        "    #   print(pred[0]*4800., p_out[0]*4800.)\n",
        "    # break\n",
        "  #print(\"Training Loss: \", i, epoch_loss.item(), time.time() - start)\n",
        "  \n",
        "  model.eval()\n",
        "  epoch_loss = 0\n",
        "  val_loop = tqdm(enumerate(val_data), total=len(val_data))\n",
        "  for i_batch, sample_batch in val_loop:\n",
        "    inp, out = sample_batch\n",
        "    batch = inp.shape[0]\n",
        "\n",
        "    p_in = (inp[:,0].reshape(batch*number,19,2).to(device))/4800.\n",
        "    v_in = inp[:,1].reshape(batch*number,19,2).to(device)/100.\n",
        "    p_out = (out[:,0].reshape(batch*number,30,2).to(device))/4800. \n",
        "    v_out = out[:,1].reshape(batch*number,30,2).to(device)/100.\n",
        "\n",
        "    pred = model(p_in, v_in)\n",
        "\n",
        "    loss = 0\n",
        "    p_criteria = nn.MSELoss()\n",
        "    p_loss = torch.sqrt(p_criteria(pred[0], p_out))\n",
        "\n",
        "    epoch_loss += p_loss\n",
        "\n",
        "    val_loop.set_description(f\"Val.  Epoch [{i + 1}/{epoch}]\")\n",
        "    val_loop.set_postfix(loss = epoch_loss.item())\n",
        "  #print(\"Validation Loss: \", epoch_loss.item())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdFKvwWzASi-"
      },
      "source": [
        "def perBatchMaxTor(array,size):\n",
        "  temp = array[:,0]\n",
        "  temp = torch.unsqueeze(temp,1)\n",
        "  temp = torch.repeat_interleave(temp,size,1)\n",
        "  return torch.max(array-temp)\n",
        "\n",
        "def zeroNormNP(array, size=19, pos=np.array([-1,-1])): # array is N,19,2\n",
        "  temp = []\n",
        "  if( np.array_equal(pos, np.array([-1,-1]))):\n",
        "    temp = array[:,0]\n",
        "  else:\n",
        "    temp = pos # should be N,2\n",
        "  temp = np.expand_dims(temp,1)\n",
        "  temp = np.repeat(temp,size,1)\n",
        "\n",
        "  return (array-temp)/200., array[:,0]\n",
        "\n",
        "def zeroNormTor(array, size=19, pos=torch.tensor([-1,-1])): # array is N,19,2\n",
        "  temp = []\n",
        "  if( np.array_equal(pos, torch.tensor([-1,-1]))):\n",
        "    temp = array[:,0]\n",
        "  else:\n",
        "    temp = pos # should be N,2\n",
        "  temp = torch.unsqueeze(temp,1)\n",
        "  temp = torch.repeat_interleave(temp,size,1)\n",
        "  return (array-temp)/200., array[:,0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wqSU86YvIgT",
        "outputId": "4e406838-ba84-48e0-af6b-170f3604d9d2"
      },
      "source": [
        "# train on multiple cars per\n",
        "import time\n",
        "\n",
        "batch_sz = 100\n",
        "train_loader = DataLoader(train_dataset,batch_size=batch_sz, shuffle = False, collate_fn=my_collate_train_multiple, num_workers=2)\n",
        "\n",
        "train_size = int(0.8 * len(train_loader.dataset))\n",
        "val_size = len(train_loader.dataset) - train_size\n",
        "train_data, val_data = torch.utils.data.random_split(train_loader.dataset, [train_size, val_size])\n",
        "\n",
        "print(\"\\nLENGTH OF TRAIN LOADER DATASET:\", len(train_loader.dataset))\n",
        "print(\"LENGTH OF TRAIN DATA:\", len(train_data), \"\\nLENGTH OF VAL DATA:\", len(val_data))\n",
        "\n",
        "train_data = DataLoader(train_data, batch_size=batch_sz, shuffle = False, collate_fn=my_collate_train_multiple, num_workers=2)\n",
        "val_data = DataLoader(val_data, batch_size=batch_sz, shuffle = False, collate_fn=my_collate_train_multiple, num_workers=2)\n",
        "model = Trajectory().to(device)\n",
        "\n",
        "my_optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# decayRate = 0.999    \n",
        "# my_lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=my_optim, gamma=decayRate)\n",
        "\n",
        "epoch = 30 # takes around 20 epochs to converge\n",
        "number = 5 # number of cars in each \n",
        "\n",
        "best_val = 100\n",
        "\n",
        "for i in range(epoch):\n",
        "\n",
        "  model.train()\n",
        "  epoch_loss = 0\n",
        "  start = time.time()\n",
        "  \n",
        "  # train_loop = tqdm(enumerate(train_data), total=len(train_data))\n",
        "\n",
        "  for i_batch, sample_batch in enumerate(train_data):\n",
        "\n",
        "    inp, out = sample_batch\n",
        "    batch = inp.shape[1]\n",
        "\n",
        "    p_in, orig = zeroNormTor(inp[0].reshape(batch*number,19,2).to(device))\n",
        "    v_in = inp[1].reshape(batch*number,19,2).to(device)/85.\n",
        "    p_out,_ = zeroNormTor(out[0].reshape(batch*number,30,2).to(device),30, orig)\n",
        "    v_out = out[1].reshape(batch*number,30,2).to(device)/85.\n",
        "\n",
        "    pred = model(p_in, v_in)\n",
        "\n",
        "\n",
        "    loss = 0\n",
        "    p_criteria = nn.MSELoss()\n",
        "    p_loss = torch.sqrt(p_criteria(pred[0], p_out))\n",
        "\n",
        "    v_criteria = nn.MSELoss()\n",
        "    v_loss = torch.sqrt(v_criteria(pred[1], v_out))\n",
        "\n",
        "    loss = p_loss + v_loss\n",
        "    epoch_loss += p_loss.item()\n",
        "\n",
        "    my_optim.zero_grad()\n",
        "    loss.backward()\n",
        "    my_optim.step()\n",
        "\n",
        "    # ur tqdm stuff broke\n",
        "    # train_loop.set_description(f\"Train Epoch [{i + 1}/{epoch}]\")\n",
        "    # train_loop.set_postfix(loss = epoch_loss.item()) \n",
        "    # my_lr_scheduler.step()\n",
        "    # if(i>2999):\n",
        "    #   temp = torch.unsqueeze(orig,1)\n",
        "      # temp = torch.repeat_interleave(temp,30,1)\n",
        "      # print((pred[0]*500+temp)[0], (p_out*500+temp)[0])\n",
        "    # break\n",
        "  print(\"Training Loss: \", i, epoch_loss, time.time() - start)\n",
        "  \n",
        "  model.eval()\n",
        "  epoch_loss = 0\n",
        "  # val_loop = tqdm(enumerate(val_data), total=len(val_data))\n",
        "  for i_batch, sample_batch in enumerate(val_data):\n",
        "    inp, out = sample_batch\n",
        "    batch = inp.shape[1]\n",
        "\n",
        "    p_in,orig = zeroNormTor(inp[0].reshape(batch*number,19,2).to(device))\n",
        "    v_in = inp[1].reshape(batch*number,19,2).to(device)/85.\n",
        "    p_out,_ = zeroNormTor(out[0].reshape(batch*number,30,2).to(device),30, orig)\n",
        "    v_out = out[1].reshape(batch*number,30,2).to(device)/85.\n",
        "\n",
        "    pred = model(p_in, v_in)\n",
        "\n",
        "    loss = 0\n",
        "    p_criteria = nn.MSELoss()\n",
        "    p_loss = torch.sqrt(p_criteria(pred[0], p_out))\n",
        "\n",
        "    epoch_loss += p_loss.item()\n",
        "\n",
        "    # val_loop.set_description(f\"Val.  Epoch [{i + 1}/{epoch}]\")\n",
        "    # val_loop.set_postfix(loss = epoch_loss.item())\n",
        "  if(epoch_loss< best_val):\n",
        "    filename = \"best.pth\"\n",
        "    state = {'epoch': i, 'state_dict': model.state_dict(),\n",
        "            'optimizer': my_optim.state_dict()}\n",
        "    torch.save(state, filename)\n",
        "    print(\"saved\")\n",
        "    best_val = epoch_loss\n",
        "\n",
        "  print(\"Validation Loss: \", epoch_loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "LENGTH OF TRAIN LOADER DATASET: 205942\n",
            "LENGTH OF TRAIN DATA: 164753 \n",
            "LENGTH OF VAL DATA: 41189\n",
            "Training Loss:  0 28.060927054844797 296.6075711250305\n",
            "saved\n",
            "Validation Loss:  5.980197741650045\n",
            "Training Loss:  1 20.87761565949768 307.6591205596924\n",
            "saved\n",
            "Validation Loss:  5.435493870638311\n",
            "Training Loss:  2 19.3822606978938 309.7150640487671\n",
            "Validation Loss:  5.555410088039935\n",
            "Training Loss:  3 18.694232560694218 309.6612434387207\n",
            "saved\n",
            "Validation Loss:  4.736429109238088\n",
            "Training Loss:  4 18.34214370744303 310.71124958992004\n",
            "saved\n",
            "Validation Loss:  4.531997323036194\n",
            "Training Loss:  5 18.0427740868181 309.95675706863403\n",
            "saved\n",
            "Validation Loss:  4.456412710249424\n",
            "Training Loss:  6 17.773441360797733 311.14957547187805\n",
            "saved\n",
            "Validation Loss:  4.381199871189892\n",
            "Training Loss:  7 17.63086613547057 309.7604398727417\n",
            "Validation Loss:  4.42516256403178\n",
            "Training Loss:  8 17.39989645173773 310.13033151626587\n",
            "Validation Loss:  4.475255382247269\n",
            "Training Loss:  9 17.22623194148764 309.0701665878296\n",
            "saved\n",
            "Validation Loss:  4.357809079810977\n",
            "Training Loss:  10 17.024786326568574 311.13201546669006\n",
            "Validation Loss:  4.373825024813414\n",
            "Training Loss:  11 16.952318370807916 309.8738420009613\n",
            "saved\n",
            "Validation Loss:  4.345512692350894\n",
            "Training Loss:  12 16.768942628521472 310.6968922615051\n",
            "saved\n",
            "Validation Loss:  4.319962861482054\n",
            "Training Loss:  13 16.664137431420386 309.9326078891754\n",
            "Validation Loss:  4.461165019311011\n",
            "Training Loss:  14 16.54998840019107 310.4470007419586\n",
            "Validation Loss:  4.441797775216401\n",
            "Training Loss:  15 16.383528046309948 310.10978865623474\n",
            "Validation Loss:  4.562233990058303\n",
            "Training Loss:  16 16.263263937551528 309.41668486595154\n",
            "Validation Loss:  4.4845772152766585\n",
            "Training Loss:  17 16.103438100311905 310.8119513988495\n",
            "Validation Loss:  4.46557851228863\n",
            "Training Loss:  18 15.985525978729129 309.9282298088074\n",
            "Validation Loss:  4.490781555883586\n",
            "Training Loss:  19 15.879532293882221 309.7825891971588\n",
            "Validation Loss:  4.423514679074287\n",
            "Training Loss:  20 15.762567412108183 309.93160939216614\n",
            "Validation Loss:  4.498067585751414\n",
            "Training Loss:  21 15.610772645100951 309.74425172805786\n",
            "Validation Loss:  4.3822300741449\n",
            "Training Loss:  22 15.485678692348301 310.3827953338623\n",
            "Validation Loss:  4.471372458152473\n",
            "Training Loss:  23 15.363124886061996 309.0616343021393\n",
            "Validation Loss:  4.394971005152911\n",
            "Training Loss:  24 15.308458453509957 309.57817220687866\n",
            "Validation Loss:  4.431817605160177\n",
            "Training Loss:  25 15.194031557999551 310.1294045448303\n",
            "Validation Loss:  4.451287516392767\n",
            "Training Loss:  26 15.100813730154186 309.74643635749817\n",
            "Validation Loss:  4.447495009750128\n",
            "Training Loss:  27 14.947403890546411 310.3860983848572\n",
            "Validation Loss:  4.350580464117229\n",
            "Training Loss:  28 14.919177090749145 309.3159234523773\n",
            "Validation Loss:  4.3244321583770216\n",
            "Training Loss:  29 14.81396803399548 310.04675006866455\n",
            "Validation Loss:  4.375913049094379\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjNAZOPL9cx2"
      },
      "source": [
        "import time \n",
        "\n",
        "batch_sz = 100\n",
        "train_loader = DataLoader(train_dataset,batch_size=batch_sz, shuffle = False, collate_fn=my_collate_train, num_workers=2)\n",
        "\n",
        "model = Trajectory().to(device)\n",
        "\n",
        "my_optim = torch.optim.Adam(model.parameters())\n",
        "\n",
        "# decayRate = 0.999\n",
        "# my_lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=my_optim, gamma=decayRate)\n",
        "\n",
        "epoch = 20 # takes around 20 epochs to converge\n",
        "number = 1 # number of cars in each \n",
        "\n",
        "for i in range(epoch):\n",
        "\n",
        "  model.train()\n",
        "  epoch_loss = 0\n",
        "  start = time.time()\n",
        "  for i_batch, sample_batch in enumerate(train_loader):\n",
        "    inp, out = sample_batch\n",
        "    batch = inp.shape[0]\n",
        "\n",
        "    p_in = (inp[:,0].reshape(batch*number,19,2).to(device))/4800. # -2400.)/2400.\n",
        "    v_in = inp[:,1].reshape(batch*number,19,2).to(device)/100.\n",
        "    p_out = (out[:,0].reshape(batch*number,30,2).to(device))/4800. # -2400.)/2400.\n",
        "    v_out = out[:,1].reshape(batch*number,30,2).to(device)/100.\n",
        "\n",
        "    pred = model(p_in, v_in)\n",
        "\n",
        "\n",
        "    loss = 0\n",
        "    p_criteria = nn.MSELoss()\n",
        "    p_loss = torch.sqrt(p_criteria(pred[0], p_out))\n",
        "\n",
        "    v_criteria = nn.MSELoss()\n",
        "    v_loss = torch.sqrt(v_criteria(pred[1], v_out))\n",
        "\n",
        "    loss = p_loss + v_loss\n",
        "    epoch_loss += p_loss\n",
        "\n",
        "    my_optim.zero_grad()\n",
        "    loss.backward()\n",
        "    my_optim.step()\n",
        "    # my_lr_scheduler.step()\n",
        "    # if(i>2999):\n",
        "    #   # print(pred[0]*2400.+2400., p_out[0]*2400.+2400.)\n",
        "    #   print(pred[0]*4800., p_out[0]*4800.)\n",
        "    # break\n",
        "  print(\"Training Loss: \", i, epoch_loss.item(), time.time() - start)\n",
        "  \n",
        "  model.eval()\n",
        "  epoch_loss = 0\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uQ2Y3O0ELNN"
      },
      "source": [
        "model.eval()\n",
        "load = True \n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "initial = 0\n",
        "\n",
        "model.eval()\n",
        "\n",
        "if(load):\n",
        "  checkpoint = torch.load('best.pth')\n",
        "  model.load_state_dict(checkpoint['state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "  print(\"=> loaded checkpoint '{}' (epoch {})\".format(filename, checkpoint['epoch']))\n",
        "  initial += int(checkpoint['epoch'])\n",
        "\n",
        "batch_sz = 100\n",
        "train_loader = DataLoader(train_dataset,batch_size=batch_sz, shuffle = False, collate_fn=my_collate_train_multiple, num_workers=2)\n",
        "\n",
        "epoch_loss =0\n",
        "batch = 60\n",
        "number = 5\n",
        "\n",
        "for i_batch, sample_batch in enumerate(train_loader):\n",
        "  inp, out = sample_batch\n",
        "  batch = inp.shape[1]\n",
        "\n",
        "  p_in = (inp[0].reshape(batch*number,19,2).to(device))/4800.\n",
        "  v_in = (inp[1].reshape(batch*number,19,2).to(device)+85.)/170.\n",
        "  p_out = (out[0].reshape(batch*number,30,2).to(device))/4800.\n",
        "  v_out = (out[1].reshape(batch*number,30,2).to(device)+85.)/170.\n",
        "\n",
        "  pred = model(p_in, v_in)\n",
        "  loss = 0\n",
        "  p_criteria = nn.MSELoss()\n",
        "  p_loss = torch.sqrt(p_criteria(pred[0], p_out))\n",
        "\n",
        "  epoch_loss += p_loss.item()\n",
        "  print(pred[0][10]*4800., p_out[10]*4800.)\n",
        "  break\n",
        "  \n",
        "print(\"Validation Loss: \", epoch_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhL6nFx1q3bm",
        "outputId": "f465a863-9665-4984-9d88-51355d8168fe"
      },
      "source": [
        "import csv \n",
        "load = True \n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "initial = 0\n",
        "\n",
        "model.eval()\n",
        "\n",
        "if(load):\n",
        "  checkpoint = torch.load('best.pth')\n",
        "  model.load_state_dict(checkpoint['state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "  print(\"=> loaded checkpoint '{}' (epoch {})\".format(filename, checkpoint['epoch']))\n",
        "  initial += int(checkpoint['epoch'])\n",
        "\n",
        "\n",
        "temp = []\n",
        "\n",
        "new_path = \"/content/new_val_in\"\n",
        "val_dataset  = ArgoverseDataset(data_path=new_path)\n",
        "\n",
        "top = []\n",
        "top.append(\"ID\")\n",
        "for i in range(60):\n",
        "  top.append(\"v\"+str(i+1))\n",
        "temp.append(top)\n",
        "\n",
        "batch = 60\n",
        "number = 1\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in val_dataset:\n",
        "      row = []\n",
        "      scene = i['scene_idx']\n",
        "      agent = i['agent_id']\n",
        "      target =0\n",
        "      for x in range(len(i['track_id'])):\n",
        "        if i['track_id'][x][0] == agent:\n",
        "          target = x\n",
        "\n",
        "      p_in = torch.LongTensor(i['p_in'])\n",
        "      v_in = torch.LongTensor(i['v_in'])\n",
        "\n",
        "      p_in = (p_in.reshape(batch*number,19,2).to(device))/4800.\n",
        "      v_in = (v_in.reshape(batch*number,19,2).to(device)+85.)/170.\n",
        "\n",
        "      pred = model(p_in, v_in)\n",
        "\n",
        "      pred_out = pred[0]*4800.\n",
        "      \n",
        "      output = pred_out[target]\n",
        "\n",
        "      row.append(scene)\n",
        "      row = row + torch.flatten(output).cpu().detach().numpy().tolist()\n",
        "      temp.append(row)\n",
        "\n",
        "with open('submission4.csv', 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerows(temp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=> loaded checkpoint 'best.pth' (epoch 18)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}